"""
Evaluator ƒë∆°n gi·∫£n cho chatbot
"""

import json
import logging
import time
from typing import Dict, List
from pathlib import Path
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Evaluator:
    """ƒê√°nh gi√° chatbot tr√™n t·∫≠p d·ªØ li·ªáu."""
    
    def __init__(self, dataset_path: str):
        with open(dataset_path, 'r', encoding='utf-8') as f:
            self.questions = json.load(f)
        logger.info(f"Loaded {len(self.questions)} questions")
    
    def evaluate(self, chatbot, max_questions: int = None) -> Dict:
        """
        ƒê√°nh gi√° chatbot.
        
        Args:
            chatbot: Chatbot c√≥ method:
                - answer_yes_no(question, statement) -> (answer, confidence)
                - answer_mcq(question, choices) -> (answer, confidence)
        """
        questions = self.questions[:max_questions] if max_questions else self.questions
        
        results = {
            "total": len(questions),
            "correct": 0,
            "by_type": {"yes_no": {"total": 0, "correct": 0}, "mcq": {"total": 0, "correct": 0}},
            "by_hops": {"1": {"total": 0, "correct": 0}, "2": {"total": 0, "correct": 0}},
            "by_answer": {"ƒê√öNG": {"total": 0, "correct": 0}, "SAI": {"total": 0, "correct": 0}},
            "errors": []
        }
        
        start = time.time()
        
        for i, q in enumerate(questions):
            if (i + 1) % 200 == 0:
                logger.info(f"Progress: {i+1}/{len(questions)}")
            
            try:
                if q['type'] == 'yes_no':
                    pred, _ = chatbot.answer_yes_no(q['question'])
                    expected = q['answer']
                else:  # mcq
                    pred, _ = chatbot.answer_mcq(q['question'], q['choices'])
                    expected = q['answer']
                
                is_correct = (pred == expected)
                
                # Update stats
                results["by_type"][q['type']]["total"] += 1
                hop_key = str(q.get('hops', 1))
                results["by_hops"][hop_key]["total"] += 1
                
                if q['type'] == 'yes_no':
                    results["by_answer"][expected]["total"] += 1
                
                if is_correct:
                    results["correct"] += 1
                    results["by_type"][q['type']]["correct"] += 1
                    results["by_hops"][hop_key]["correct"] += 1
                    if q['type'] == 'yes_no':
                        results["by_answer"][expected]["correct"] += 1
                else:
                    results["errors"].append({
                        "id": q['id'],
                        "question": q['question'],
                        "expected": expected,
                        "predicted": pred,
                        "type": q['type'],
                        "hops": q.get('hops', 1)
                    })
                    
            except Exception as e:
                logger.error(f"Error on Q{q['id']}: {e}")
                results["errors"].append({"id": q['id'], "error": str(e)})
        
        # Calculate accuracy
        results["accuracy"] = results["correct"] / results["total"] * 100
        
        for t in results["by_type"]:
            total = results["by_type"][t]["total"]
            if total > 0:
                results["by_type"][t]["accuracy"] = results["by_type"][t]["correct"] / total * 100
        
        for h in results["by_hops"]:
            total = results["by_hops"][h]["total"]
            if total > 0:
                results["by_hops"][h]["accuracy"] = results["by_hops"][h]["correct"] / total * 100
        
        for a in results["by_answer"]:
            total = results["by_answer"][a]["total"]
            if total > 0:
                results["by_answer"][a]["accuracy"] = results["by_answer"][a]["correct"] / total * 100
        
        results["elapsed"] = time.time() - start
        results["timestamp"] = datetime.now().isoformat()
        
        return results
    
    def print_results(self, results: Dict):
        """In k·∫øt qu·∫£."""
        print("\n" + "=" * 50)
        print("üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å")
        print("=" * 50)
        
        print(f"\n‚úÖ T·ªïng: {results['correct']}/{results['total']}")
        print(f"üìà ƒê·ªô ch√≠nh x√°c: {results['accuracy']:.2f}%")
        
        print("\n--- Theo lo·∫°i c√¢u h·ªèi ---")
        for t, s in results["by_type"].items():
            if s["total"] > 0:
                print(f"  {t}: {s['correct']}/{s['total']} ({s.get('accuracy', 0):.2f}%)")
        
        print("\n--- Theo s·ªë hop ---")
        for h, s in results["by_hops"].items():
            if s["total"] > 0:
                print(f"  {h}-hop: {s['correct']}/{s['total']} ({s.get('accuracy', 0):.2f}%)")
        
        print("\n--- Theo ƒë√°p √°n (ƒê√∫ng/Sai) ---")
        for a, s in results["by_answer"].items():
            if s["total"] > 0:
                print(f"  {a}: {s['correct']}/{s['total']} ({s.get('accuracy', 0):.2f}%)")
        
        print(f"\n‚è±Ô∏è Th·ªùi gian: {results['elapsed']:.2f}s")
        
        if results["errors"][:3]:
            print("\n--- M·ªôt s·ªë l·ªói ---")
            for e in results["errors"][:3]:
                print(f"  Q: {e.get('question', '')[:60]}...")
                print(f"     Expected: {e.get('expected')} | Got: {e.get('predicted')}")
    
    def save_results(self, results: Dict, filepath: str):
        """L∆∞u k·∫øt qu·∫£."""
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        save_data = results.copy()
        save_data["errors"] = results["errors"][:50]  # Ch·ªâ l∆∞u 50 l·ªói ƒë·∫ßu
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        logger.info(f"Saved to {filepath}")


def main():
    from chatbot.graph_chatbot import GraphChatbot
    
    # Kh·ªüi t·∫°o chatbot
    chatbot = GraphChatbot()
    if not chatbot.initialize():
        print("Failed to initialize chatbot")
        return
    
    # ƒê√°nh gi√°
    evaluator = Evaluator("data/evaluation/eval_dataset.json")
    results = evaluator.evaluate(chatbot)
    evaluator.print_results(results)
    evaluator.save_results(results, "reports/graph_chatbot_eval.json")


if __name__ == "__main__":
    main()
