# QUY TRÃŒNH THU THáº¬P Dá»® LIá»†U - VN FOOTBALL GRAPH

## ğŸ“‹ Tá»”NG QUAN

Dá»± Ã¡n **VN Football Graph** sá»­ dá»¥ng pipeline hoÃ n toÃ n tá»± Ä‘á»™ng Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  xÃ¢y dá»±ng knowledge graph vá» bÃ³ng Ä‘Ã¡ Viá»‡t Nam. Nguá»“n dá»¯ liá»‡u chÃ­nh lÃ  **Wikipedia tiáº¿ng Viá»‡t**.

### ğŸ“Š Thá»‘ng kÃª dá»¯ liá»‡u thá»±c táº¿ Ä‘Ã£ thu tháº­p:
- **1,229 trang JSON thÃ´** tá»« Wikipedia
- **557 cáº§u thá»§** (players)
- **106 cÃ¢u láº¡c bá»™** (clubs)
- **74 huáº¥n luyá»‡n viÃªn** (coaches)
- **541 entities parsed** thÃ nh cÃ´ng
- **526 cáº§u thá»§ clean** sau normalize
- **17 loáº¡i relationships** khÃ¡c nhau
- **HÆ¡n 1.3M edges** trong graph (teammate lÃ  nhiá»u nháº¥t)

---

## ğŸ”„ LUá»’NG Dá»® LIá»†U (DATA PIPELINE)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Wikipedia VI   â”‚  (Nguá»“n dá»¯ liá»‡u)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. CRAWLING    â”‚  Scraper â†’ data/raw/*.json
â”‚  (Thu tháº­p)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. PARSING     â”‚  Parser â†’ data/parsed/*.jsonl
â”‚  (PhÃ¢n tÃ­ch)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. NORMALIZE   â”‚  Processor â†’ data/processed/*.csv
â”‚  (Chuáº©n hÃ³a)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. BUILD RELS  â”‚  Relationship Builder â†’ data/edges/*.csv
â”‚  (XÃ¢y quan há»‡)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. IMPORT      â”‚  Neo4j Importer â†’ Neo4j Database
â”‚  (Nháº­p DB)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. VALIDATE    â”‚  Validator â†’ reports/import_report.txt
â”‚  (Kiá»ƒm tra)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CHI TIáº¾T Tá»ªNG BÆ¯á»šC

### **BÆ¯á»šC 1: CRAWLING - THU THáº¬P Dá»® LIá»†U**

#### ğŸ“ File: `scraper/wikipedia_crawler.py`

#### CÃ¡ch hoáº¡t Ä‘á»™ng:
1. **Káº¿t ná»‘i Wikipedia API** sá»­ dá»¥ng thÆ° viá»‡n `mwclient`
2. **Duyá»‡t cÃ¡c danh má»¥c** (categories) Ä‘Æ°á»£c cáº¥u hÃ¬nh trong `config/config.py`
3. **Láº¥y thÃ´ng tin trang** qua MediaWiki API
4. **LÆ°u dá»¯ liá»‡u thÃ´** dáº¡ng JSON

#### CÃ¡c danh má»¥c Ä‘Æ°á»£c thu tháº­p:
```python
WIKI_CATEGORIES = {
    # Cáº§u thá»§
    "Cáº§u thá»§ bÃ³ng Ä‘Ã¡ Viá»‡t Nam": "player",
    "Cáº§u thá»§ bÃ³ng Ä‘Ã¡ ná»¯ Viá»‡t Nam": "player",
    "Cáº§u thá»§ Ä‘á»™i tuyá»ƒn bÃ³ng Ä‘Ã¡ quá»‘c gia Viá»‡t Nam": "player",
    "Quáº£ bÃ³ng vÃ ng Viá»‡t Nam": "player",
    
    # Huáº¥n luyá»‡n viÃªn
    "Huáº¥n luyá»‡n viÃªn bÃ³ng Ä‘Ã¡ Viá»‡t Nam": "coach",
    
    # CÃ¢u láº¡c bá»™
    "CÃ¢u láº¡c bá»™ bÃ³ng Ä‘Ã¡ Viá»‡t Nam": "club",
    
    # Äá»™i tuyá»ƒn
    "Äá»™i tuyá»ƒn bÃ³ng Ä‘Ã¡ quá»‘c gia Viá»‡t Nam": "national_team",
    "Äá»™i tuyá»ƒn bÃ³ng Ä‘Ã¡ ná»¯ quá»‘c gia Viá»‡t Nam": "national_team",
    
    # SÃ¢n váº­n Ä‘á»™ng
    "Äá»‹a Ä‘iá»ƒm bÃ³ng Ä‘Ã¡ Viá»‡t Nam": "stadium",
    
    # Giáº£i Ä‘áº¥u
    "Giáº£i bÃ³ng Ä‘Ã¡ Viá»‡t Nam": "competition",
}
```

#### Dá»¯ liá»‡u thu tháº­p Ä‘Æ°á»£c (JSON Structure):
```json
{
  "page_id": 3289965,
  "page_title": "LÆ°u Ngá»c Mai",
  "entity_type": "player",
  "full_url": "https://vi.wikipedia.org/wiki/LÆ°u_Ngá»c_Mai",
  "wikitext": "{{ThÃ´ng tin tiá»ƒu sá»­ bÃ³ng Ä‘Ã¡\n| name = LÆ°u Ngá»c Mai\n| fullname = LÆ°u Ngá»c Mai\n...",
  "last_revision_id": 12345678,
  "fetched_at": "2024-12-02T15:22:30Z"
}
```

**Fields chi tiáº¿t:**
- **page_id**: ID duy nháº¥t cá»§a trang Wikipedia (int)
- **page_title**: TiÃªu Ä‘á» trang (string)
- **entity_type**: Loáº¡i entity (player/coach/club...)
- **full_url**: URL Ä‘áº§y Ä‘á»§ Ä‘áº¿n trang Wikipedia
- **wikitext**: Ná»™i dung Wikitext Ä‘áº§y Ä‘á»§ (cÃ³ thá»ƒ ráº¥t dÃ i, 3-170KB)
- **last_revision_id**: ID cá»§a revision cuá»‘i cÃ¹ng
- **fetched_at**: Timestamp khi crawl (ISO 8601)

#### CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng chi tiáº¿t:

**1. Káº¿t ná»‘i API:**
```python
site = mwclient.Site(
    "vi.wikipedia.org",
    path="/w/",
    clients_useragent="VietnamFootballKG/1.0 (...)"
)
```

**2. Duyá»‡t categories:**
```python
# Láº¥y category object
category = site.categories["Cáº§u thá»§ bÃ³ng Ä‘Ã¡ Viá»‡t Nam"]

# Duyá»‡t tá»«ng member trong category
for member in category.members():
    if member.namespace == 0:  # Main article (khÃ´ng pháº£i subcategory)
        page = site.pages[member.name]
        wikitext = page.text()  # Láº¥y toÃ n bá»™ wikitext
        # LÆ°u vÃ o JSON...
```

**3. Rate Limiting:**
- Delay **1 giÃ¢y** giá»¯a má»—i request (`time.sleep(1.0)`)
- Retry **3 láº§n** náº¿u tháº¥t báº¡i vá»›i backoff 5 giÃ¢y
- User-Agent: `"VietnamFootballKG/1.0"`
- Connection pool reuse Ä‘á»ƒ tá»‘i Æ°u

**4. Caching thÃ´ng minh:**
```python
# Load cached page IDs tá»« filenames
cached_ids = set()
for file in data/raw/*.json:
    page_id = extract_id_from_filename(file)  # player_123456.json â†’ 123456
    cached_ids.add(page_id)

# Skip náº¿u Ä‘Ã£ cÃ³
if page_id in cached_ids and cache_enabled:
    skip()
```

**5. Error Handling:**
- Xá»­ lÃ½ `ConnectionError`, `Timeout`
- Retry logic vá»›i exponential backoff
- Log lá»—i nhÆ°ng khÃ´ng dá»«ng pipeline
- Stats tracking: `{"fetched": X, "cached": Y, "failed": Z}`

#### Output thá»±c táº¿:
```
data/raw/
â”œâ”€â”€ player_3289965.json      # LÆ°u Ngá»c Mai (3.9KB)
â”œâ”€â”€ club_31345.json          # Má»™t CLB (85KB - cÃ³ nhiá»u data)
â”œâ”€â”€ club_37360.json          # CLB khÃ¡c (171KB - ráº¥t chi tiáº¿t!)
â”œâ”€â”€ coach_345678.json        # HLV
â”œâ”€â”€ competition_xxx.json     # Giáº£i Ä‘áº¥u
â””â”€â”€ ... (1,229 files total)
```

**File sizes:**
- Cáº§u thá»§: 3-15KB (trung bÃ¬nh ~8KB)
- CÃ¢u láº¡c bá»™: 5-171KB (lá»›n hÆ¡n nhiá»u do cÃ³ lá»‹ch sá»­)
- Huáº¥n luyá»‡n viÃªn: 10-30KB
- Giáº£i Ä‘áº¥u: 20-100KB

#### Lá»‡nh cháº¡y:
```bash
# Thu tháº­p táº¥t cáº£
make crawl
# hoáº·c
python -m scraper.wikipedia_crawler --fetch-all

# Thu tháº­p category cá»¥ thá»ƒ
python -m scraper.wikipedia_crawler --category "Cáº§u thá»§ bÃ³ng Ä‘Ã¡ Viá»‡t Nam" --entity-type player

# Bá» cache vÃ  táº£i láº¡i
python -m scraper.wikipedia_crawler --fetch-all --no-cache
```

---

### **BÆ¯á»šC 2: PARSING - PHÃ‚N TÃCH WIKITEXT**

#### ğŸ“ File: `parser/infobox_parser.py`

#### CÃ¡ch hoáº¡t Ä‘á»™ng:
1. **Äá»c file JSON** tá»« `data/raw/`
2. **Parse Wikitext** sá»­ dá»¥ng `mwparserfromhell`
3. **TrÃ­ch xuáº¥t Infobox** (cÃ¡c template nhÆ° `{{Infobox cáº§u thá»§ bÃ³ng Ä‘Ã¡}}`)
4. **Mapping fields** theo cáº¥u hÃ¬nh
5. **LÆ°u dáº¡ng JSONL** (JSON Lines)

#### CÃ¡c Infobox Ä‘Æ°á»£c há»— trá»£:
```python
INFOBOX_TEMPLATES = {
    "player": [
        "Infobox cáº§u thá»§ bÃ³ng Ä‘Ã¡",      # Tiáº¿ng Viá»‡t
        "Infobox football biography",    # Tiáº¿ng Anh
        "Football player infobox",
        "Cáº§u thá»§ bÃ³ng Ä‘Ã¡",
    ],
    "coach": [
        "Infobox huáº¥n luyá»‡n viÃªn bÃ³ng Ä‘Ã¡",
        "Infobox football manager",
        "Football manager infobox",
    ],
    "club": [
        "Infobox cÃ¢u láº¡c bá»™ bÃ³ng Ä‘Ã¡",
        "Infobox football club",
    ],
    "national_team": [
        "Infobox Ä‘á»™i tuyá»ƒn bÃ³ng Ä‘Ã¡ quá»‘c gia",
        "Infobox national football team",
    ],
}
```

#### Field Mappings:
Parser tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i tÃªn trÆ°á»ng tiáº¿ng Viá»‡t sang tiáº¿ng Anh:
```python
FIELD_MAPPINGS = {
    "tÃªn": "name",
    "tÃªn Ä‘áº§y Ä‘á»§": "full_name",
    "ngÃ y sinh": "birth_date",
    "nÆ¡i sinh": "birth_place",
    "vá»‹ trÃ­": "position",
    "cÃ¢u láº¡c bá»™": "current_club",
    "quá»‘c tá»‹ch": "nationality",
    "chiá»u cao": "height",
    "sá»‘ Ã¡o": "shirt_number",
    # ... vÃ  nhiá»u trÆ°á»ng khÃ¡c
}
```

#### Xá»­ lÃ½ Career History:
Parser trÃ­ch xuáº¥t lá»‹ch sá»­ sá»± nghiá»‡p tá»« infobox:
- **NÄƒm** (years)
- **CÃ¢u láº¡c bá»™** (club)
- **Sá»‘ tráº­n** (appearances)
- **BÃ n tháº¯ng** (goals)

#### LÃ m sáº¡ch dá»¯ liá»‡u:
- Loáº¡i bá» Wikimarkup (`[[link]]` â†’ `link`)
- Loáº¡i bá» HTML tags
- Loáº¡i bá» references (`<ref>...</ref>`)
- Chuáº©n hÃ³a whitespace
- Loáº¡i bá» nickname trong ngoáº·c Ä‘Æ¡n

#### Parsing Logic chi tiáº¿t:

**1. TÃ¬m Infobox Template:**
```python
wikicode = mwparserfromhell.parse(wikitext)
templates = wikicode.filter_templates()

# TÃ¬m infobox phÃ¹ há»£p
for template in templates:
    name = str(template.name).strip().lower()
    if name in ["thÃ´ng tin tiá»ƒu sá»­ bÃ³ng Ä‘Ã¡", "infobox football biography"]:
        infobox = template
        break
```

**2. TrÃ­ch xuáº¥t parameters:**
```python
params = {}
for param in infobox.params:
    field_name = param.name.strip()  # "tÃªn Ä‘áº§y Ä‘á»§"
    field_value = param.value.strip()  # "Nguyá»…n CÃ´ng PhÆ°á»£ng"
    
    # Normalize field name
    normalized = FIELD_MAPPINGS.get(field_name, field_name)
    params[normalized] = field_value
```

**3. Clean Wikitext:**
```python
# Loáº¡i bá» wiki markup
"[[HoÃ ng Anh Gia Lai]]" â†’ "HoÃ ng Anh Gia Lai"
"[[Nghá»‡ An|tá»‰nh Nghá»‡ An]]" â†’ "tá»‰nh Nghá»‡ An"

# Loáº¡i bá» references
"Text<ref>citation</ref>" â†’ "Text"

# Parse templates
"{{birth date|1995|1|21}}" â†’ "1995-01-21"
"{{height|m=1.68}}" â†’ "1.68 m"
```

**4. Parse Career History:**
```python
# Tá»« numbered parameters: clubs1, years1, caps1, goals1...
history = []
for i in range(1, 20):
    if f"clubs{i}" in params:
        entry = {
            "club_name": params[f"clubs{i}"],
            "from_year": parse_year(params.get(f"years{i}", "").split("-")[0]),
            "to_year": parse_year(params.get(f"years{i}", "").split("-")[1]),
            "appearances": int(params.get(f"caps{i}", 0)),
            "goals": int(params.get(f"goals{i}", 0))
        }
        history.append(entry)
```

#### Output thá»±c táº¿:
```
data/parsed/
â”œâ”€â”€ players.jsonl           # 541 dÃ²ng (cáº§u thá»§)
â”œâ”€â”€ clubs.jsonl             # 79 dÃ²ng
â”œâ”€â”€ coaches.jsonl           # 9 dÃ²ng
â”œâ”€â”€ coachs.jsonl            # 64 dÃ²ng (typo - cÃ³ cáº£ 2 files)
â”œâ”€â”€ national_teams.jsonl    # 18 dÃ²ng
â”œâ”€â”€ competitions.jsonl      # 392 dÃ²ng (nhiá»u mÃ¹a giáº£i)
â”œâ”€â”€ stadiums.jsonl          # 42 dÃ²ng
â””â”€â”€ awards.jsonl            # 1 dÃ²ng
```

**VÃ­ dá»¥ thá»±c táº¿ tá»« `players.jsonl` (LÆ°u Ngá»c Mai):**
```json
{
    "wiki_id": 3289965,
    "wiki_url": "https://vi.wikipedia.org/wiki/LÆ°u_Ngá»c_Mai",
    "wiki_title": "LÆ°u Ngá»c Mai",
    "name": "LÆ°u Ngá»c Mai",
    "full_name": "LÆ°u Ngá»c Mai",
    "date_of_birth": null,
    "place_of_birth": "SÃ i GÃ²n, Viá»‡t Nam Cá»™ng hÃ²a",
    "nationality": null,
    "position": "FW",
    "height": "",
    "current_club": "ThÃ nh phá»‘ Há»“ ChÃ­ Minh",
    "clubs_history": [
        {
            "club_name": "ThÃ nh phá»‘ Há»“ ChÃ­ Minh",
            "from_year": 1998,
            "to_year": 2003
        }
    ],
    "national_team_history": [
        {
            "club_name": "Viá»‡t Nam",
            "from_year": 1998,
            "to_year": 2003
        }
    ]
}
```

**Xá»­ lÃ½ special cases:**
- `null` values: Khi field khÃ´ng cÃ³ trong infobox
- Empty strings: Khi cÃ³ field nhÆ°ng khÃ´ng cÃ³ value
- Position normalization: "Tiá»n Ä‘áº¡o" â†’ "FW"
- Date parsing: Xá»­ lÃ½ nhiá»u format (ISO, Vietnamese, templates)
- Career history: Parse tá»« numbered params (clubs1, clubs2...)

#### Lá»‡nh cháº¡y:
```bash
# Parse táº¥t cáº£
make parse
# hoáº·c
python -m parser.infobox_parser --parse-all

# Parse entity type cá»¥ thá»ƒ
python -m parser.infobox_parser --entity-type player
```

---

### **BÆ¯á»šC 3: NORMALIZE - CHUáº¨N HÃ“A Dá»® LIá»†U**

#### ğŸ“ File: `processor/entity_builder.py`

#### CÃ¡ch hoáº¡t Ä‘á»™ng:
1. **Äá»c JSONL** vÃ o Pandas DataFrame
2. **Loáº¡i bá» báº£n ghi thiáº¿u field báº¯t buá»™c**
3. **Deduplication** (loáº¡i bá» trÃ¹ng láº·p)
4. **Táº¡o canonical names** cho cÃ¡c entity giá»‘ng nhau
5. **XÃ¢y dá»±ng báº£ng tham chiáº¿u** (positions, nationalities)
6. **Xuáº¥t CSV** sáº¡ch

#### Required Fields:
```python
REQUIRED_FIELDS = {
    "player": ["wiki_id", "name"],
    "coach": ["wiki_id", "name"],
    "club": ["wiki_id", "name"],
    "national_team": ["wiki_id", "name"],
}
```

#### Deduplication Logic:
```python
DEDUP_FIELDS = {
    "player": ["name", "birth_date"],  # TrÃ¹ng tÃªn + ngÃ y sinh â†’ cÃ¹ng ngÆ°á»i
    "coach": ["name", "birth_date"],
    "club": ["name"],
    "national_team": ["name"],
}
```

VÃ­ dá»¥:
- "Nguyá»…n CÃ´ng PhÆ°á»£ng" sinh 1995-01-21 (wiki_id=123)
- "CÃ´ng PhÆ°á»£ng" sinh 1995-01-21 (wiki_id=456)
â†’ **ÄÆ°á»£c merge**, giá»¯ wiki_id=123, canonical_name="Nguyá»…n CÃ´ng PhÆ°á»£ng"

#### Reference Tables:
Táº¡o báº£ng chuáº©n cho:
- **Positions** (Vá»‹ trÃ­): Tiá»n Ä‘áº¡o, Trung vá»‡, Thá»§ mÃ´n...
- **Nationalities** (Quá»‘c tá»‹ch): Viá»‡t Nam, Nháº­t Báº£n, HÃ n Quá»‘c...

#### Output:
```
data/processed/
â”œâ”€â”€ players_clean.csv          # Cáº§u thá»§ sáº¡ch
â”œâ”€â”€ coaches_clean.csv          # HLV sáº¡ch
â”œâ”€â”€ clubs_clean.csv            # CLB sáº¡ch
â”œâ”€â”€ national_teams_clean.csv   # Äá»™i tuyá»ƒn sáº¡ch
â”œâ”€â”€ positions_reference.csv    # Báº£ng vá»‹ trÃ­
â””â”€â”€ nationalities_reference.csv  # Báº£ng quá»‘c tá»‹ch
```

#### Chi tiáº¿t Deduplication:

**Case thá»±c táº¿: Maxwell Eyerakpo / Äinh HoÃ ng Max**
```python
# Entry 1 (wiki_id: 388228)
name: "Maxwell Eyerakpo"
birth_date: null
birth_place: "Abuja, Nigeria"

# Entry 2 (cÃ³ thá»ƒ cÃ³)
name: "Äinh HoÃ ng Max"
birth_date: null
birth_place: "Abuja, Nigeria"

# â†’ Merge dá»±a trÃªn birth_place + manual check
# â†’ canonical_name: "Maxwell EyerakpoÄinh HoÃ ng Max"
```

**Normalization process:**
```python
# 1. Remove missing required fields
df = df[df['wiki_id'].notna()]
df = df[df['name'].notna()]

# 2. Deduplicate
df = df.drop_duplicates(subset=['name', 'date_of_birth'], keep='first')

# 3. Create canonical names
# Náº¿u cÃ³ nhiá»u tÃªn giá»‘ng nhau â†’ giá»¯ tÃªn Ä‘áº§y Ä‘á»§ nháº¥t
```

**Reference Tables táº¡o ra:**

`positions_reference.csv`:
```csv
position_code,position_name,position_name_vi
GK,Goalkeeper,Thá»§ mÃ´n
DF,Defender,Háº­u vá»‡
MF,Midfielder,Tiá»n vá»‡
FW,Forward,Tiá»n Ä‘áº¡o
CB,Center Back,Trung vá»‡
FB,Full Back,Háº­u vá»‡ cÃ¡nh
```

`nationalities_reference.csv`:
```csv
nationality_code,nationality_name
VN,Vietnam
BR,Brasil
NG,Nigeria
JP,Japan
```

Cáº¥u trÃºc `players_clean.csv` thá»±c táº¿ (ráº¥t nhiá»u columns):
```csv
wiki_id,name,canonical_name,full_name,date_of_birth,birth_year,place_of_birth,province,nationality_normalized,position,position_normalized,height,height_m,current_club,clubs_history,national_team_history,club_appearances,club_goals,national_team_appearances,national_team_goals,is_national_team_player,career_start_year,career_end_year,years_active,wiki_url,wiki_title
422045,"Huá»³nh Kesley Alves","Huá»³nh Kesley Alves","Huá»³nh Kesley Alves",,"","Palmeiras Bahia Brasil","","Vietnam","FW","FW","1.80 m",1.8,"","[{""club_name"": ""Portuguesa"", ""appearances"": 18, ""goals"": 1, ""from_year"": 2002, ""to_year"": 2003}...]","[{""club_name"": ""Viá»‡t Nam"", ""appearances"": 18, ""goals"": 1...}]",285,147,18,1,True,2002.0,2024.0,23.0,"https://vi.wikipedia.org/wiki/Huá»³nh_Kesley_Alves","Huá»³nh Kesley Alves"
```

**CÃ¡c computed fields:**
- `birth_year`: Extract tá»« date_of_birth
- `height_m`: Parse "1.80 m" â†’ 1.8 (float)
- `is_national_team_player`: True náº¿u cÃ³ national_team_history
- `years_active`: career_end_year - career_start_year
- `club_appearances`: Sum táº¥t cáº£ appearances trong clubs_history
- `club_goals`: Sum táº¥t cáº£ goals
- `province`: Extract tá»« place_of_birth (náº¿u cÃ³)

#### Lá»‡nh cháº¡y:
```bash
# Normalize táº¥t cáº£
make normalize
# hoáº·c
python -m processor.entity_builder --normalize-all
```

---

### **BÆ¯á»šC 4: BUILD RELATIONSHIPS - XÃ‚Y Dá»°NG QUAN Há»†**

#### ğŸ“ File: `processor/relationship_builder.py`

#### CÃ¡ch hoáº¡t Ä‘á»™ng:
1. **Äá»c CSV entities** tá»« `data/processed/`
2. **XÃ¢y dá»±ng 3 layers quan há»‡**
3. **Export edge tables** dáº¡ng CSV

#### 3 Layers Relationships:

##### **LAYER 1: Direct Relationships** (tá»« infobox)
- `PLAYED_FOR`: Player â†’ Club
- `PLAYED_FOR_NATIONAL`: Player â†’ National Team
- `COACHED`: Coach â†’ Club
- `COACHED_NATIONAL`: Coach â†’ National Team

##### **LAYER 2: Derived Relationships** (suy luáº­n tá»« dá»¯ liá»‡u)
- `TEAMMATE`: Player â†” Player (cÃ¹ng CLB, thá»i gian trÃ¹ng nhau)
- `UNDER_COACH`: Player â†’ Coach (cÃ¹ng CLB, thá»i gian trÃ¹ng nhau)
- `NATIONAL_TEAMMATE`: Player â†” Player (cÃ¹ng Ä‘á»™i tuyá»ƒn)

##### **LAYER 3: Semantic Relationships** (tá»« thuá»™c tÃ­nh)
- `HAS_POSITION`: Player â†’ Position
- `HAS_NATIONALITY`: Player/Coach â†’ Nationality

#### Thuáº­t toÃ¡n tÃ¬m Teammates:
```python
# VÃ­ dá»¥: TÃ¬m Ä‘á»“ng Ä‘á»™i cá»§a CÃ´ng PhÆ°á»£ng táº¡i HAGL (2015-2020)
for player in all_players:
    if player.club == "HAGL":
        if player.years overlap with "2015-2020":
            â†’ create edge: CÃ´ng PhÆ°á»£ng -[TEAMMATE]-> player
```

#### Output:
```
data/edges/
â”œâ”€â”€ played_for.csv              # Player â†’ Club
â”œâ”€â”€ played_for_national.csv     # Player â†’ National Team
â”œâ”€â”€ coached.csv                 # Coach â†’ Club
â”œâ”€â”€ coached_national.csv        # Coach â†’ National Team
â”œâ”€â”€ teammate.csv                # Player â†” Player
â”œâ”€â”€ under_coach.csv             # Player â†’ Coach
â”œâ”€â”€ national_teammate.csv       # Player â†” Player
â”œâ”€â”€ has_position.csv            # Player â†’ Position
â””â”€â”€ has_nationality.csv         # Player/Coach â†’ Nationality
```

#### Chi tiáº¿t thuáº­t toÃ¡n xÃ¢y relationships:

**LAYER 1: Direct from infobox data**

`played_for.csv` - Tá»« clubs_history:
```csv
from_player_id,to_club_id,to_club_name,from_year,to_year,appearances,goals
422045,,Portuguesa,2002.0,2003.0,18.0,1.0
422045,,Vasco da Gama,2003.0,2003.0,20.0,9.0
422045,,Matsubara,2005.0,2005.0,10.0,4.0
```
*Note: `to_club_id` NULL vÃ¬ club chÆ°a match Ä‘Æ°á»£c (náº±m ngoÃ i VN)*

`played_for_national.csv` - Tá»« national_team_history:
```csv
from_player_id,to_team_id,to_team_name,from_year,to_year,appearances,goals
422045,,Viá»‡t Nam,2002.0,2003.0,18.0,1.0
```

**LAYER 2: Derived - Teammate relationships**

Thuáº­t toÃ¡n tÃ¬m Ä‘á»“ng Ä‘á»™i:
```python
# Vá»›i má»—i cáº·p cáº§u thá»§ (p1, p2)
for club_entry_1 in p1.clubs_history:
    for club_entry_2 in p2.clubs_history:
        # Kiá»ƒm tra cÃ¹ng CLB
        if club_entry_1.club_name == club_entry_2.club_name:
            # Kiá»ƒm tra thá»i gian overlap
            start = max(club_entry_1.from_year, club_entry_2.from_year)
            end = min(club_entry_1.to_year, club_entry_2.to_year)
            
            if start <= end:  # CÃ³ overlap
                create_edge(p1, p2, "TEAMMATE", club_name, start, end)
```

`teammate.csv` (438K - file lá»›n nháº¥t, 6,000+ rows):
```csv
from_player_id,to_player_id,club_name,from_year,to_year
123456,234567,HoÃ ng Anh Gia Lai,2015,2018
123456,345678,HoÃ ng Anh Gia Lai,2016,2020
```

`national_teammate.csv` (1.3MB - HUGE, hÃ ng chá»¥c nghÃ¬n rows):
```csv
from_player_id,to_player_id,team_name,from_year,to_year
123456,234567,Viá»‡t Nam,2015,2020
```
*LÃ½ do lá»›n: Má»—i cáº§u thá»§ Ä‘á»™i tuyá»ƒn VN cÃ³ ~50-100 Ä‘á»“ng Ä‘á»™i*

**LAYER 3: Semantic relationships**

`has_position.csv`:
```csv
from_player_id,to_position_code
422045,FW
388228,MF
2361483,GK
```

`has_nationality.csv`:
```csv
from_entity_id,entity_type,to_nationality_code
422045,player,VN
388228,player,VN
```

**CÃ¡c edges khÃ¡c:**

`under_coach.csv` (2.7K):
```csv
from_player_id,to_coach_id,club_name,from_year,to_year
```

`coached.csv` (17K):
```csv
from_coach_id,to_club_id,from_year,to_year
```

`born_in.csv` (9.2K):
```csv
from_player_id,to_province_name
123456,Nghá»‡ An
234567,HÃ  Ná»™i
```

#### Lá»‡nh cháº¡y:
```bash
# Build táº¥t cáº£ relationships
make build-rels
# hoáº·c
python -m processor.relationship_builder --build-all

# Build relationship cá»¥ thá»ƒ
python -m processor.relationship_builder --build played_for
```

---

### **BÆ¯á»šC 5: IMPORT TO NEO4J - NHáº¬P VÃ€O DATABASE**

#### ğŸ“ File: `neo4j_import/import_to_neo4j.py`

#### CÃ¡ch hoáº¡t Ä‘á»™ng:
1. **Káº¿t ná»‘i Neo4j Aura** qua Python driver
2. **Táº¡o constraints & indexes**
3. **Import nodes** tá»« CSV (batch processing)
4. **Import relationships** tá»« CSV
5. **Verify import** vÃ  bÃ¡o cÃ¡o thá»‘ng kÃª

#### Káº¿t ná»‘i Neo4j:
```python
# Neo4j Aura connection
NEO4J_URI = "neo4j+s://xxxxx.databases.neo4j.io"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = os.environ.get("NEO4J_PASSWORD")
```

#### Schema Setup:
```cypher
-- Constraints (Ä‘áº£m báº£o wiki_id unique)
CREATE CONSTRAINT player_wiki_id IF NOT EXISTS
FOR (p:Player) REQUIRE p.wiki_id IS UNIQUE;

CREATE CONSTRAINT club_wiki_id IF NOT EXISTS
FOR (c:Club) REQUIRE c.wiki_id IS UNIQUE;

-- Indexes (tá»‘i Æ°u query)
CREATE INDEX player_name IF NOT EXISTS
FOR (p:Player) ON (p.name);

CREATE INDEX player_position IF NOT EXISTS
FOR (p:Player) ON (p.position);
```

#### Chi tiáº¿t Import Process:

**1. Read CSV Files:**
```python
import csv
import pandas as pd

# Load players
players_df = pd.read_csv('data/processed/players_clean.csv')
players_data = players_df.to_dict('records')  # List of dicts

# Load edges
played_for_df = pd.read_csv('data/edges/played_for.csv')
```

**2. Create Constraints (trÆ°á»›c khi import):**
```cypher
-- Ensure wiki_id unique
CREATE CONSTRAINT player_wiki_id IF NOT EXISTS
FOR (p:Player) REQUIRE p.wiki_id IS UNIQUE;

CREATE CONSTRAINT club_wiki_id IF NOT EXISTS
FOR (c:Club) REQUIRE c.wiki_id IS UNIQUE;

CREATE CONSTRAINT coach_wiki_id IF NOT EXISTS
FOR (co:Coach) REQUIRE co.wiki_id IS UNIQUE;

-- Indexes for faster queries
CREATE INDEX player_name IF NOT EXISTS
FOR (p:Player) ON (p.name);

CREATE INDEX player_position IF NOT EXISTS
FOR (p:Player) ON (p.position);

CREATE INDEX club_name IF NOT EXISTS
FOR (c:Club) ON (c.name);
```

**3. Batch Import Nodes:**
```python
BATCH_SIZE = 500  # 500 records per transaction

def import_players(session, players_data):
    for i in range(0, len(players_data), BATCH_SIZE):
        batch = players_data[i:i+BATCH_SIZE]
        
        query = """
        UNWIND $batch AS row
        MERGE (p:Player {wiki_id: row.wiki_id})
        SET p.name = row.name,
            p.full_name = row.full_name,
            p.date_of_birth = row.date_of_birth,
            p.place_of_birth = row.place_of_birth,
            p.position = row.position,
            p.height = row.height_m,
            p.nationality = row.nationality_normalized,
            p.current_club = row.current_club,
            p.career_start = row.career_start_year,
            p.career_end = row.career_end_year,
            p.total_appearances = row.club_appearances,
            p.total_goals = row.club_goals,
            p.is_national_player = row.is_national_team_player
        """
        
        result = session.run(query, batch=batch)
        summary = result.consume()
        print(f"Created {summary.counters.nodes_created} nodes")
```

**4. Import Relationships:**
```python
def import_played_for(session, edges_data):
    query = """
    UNWIND $batch AS row
    MATCH (p:Player {wiki_id: row.from_player_id})
    MATCH (c:Club {name: row.to_club_name})  // Match by name náº¿u khÃ´ng cÃ³ ID
    MERGE (p)-[r:PLAYED_FOR]->(c)
    SET r.from_year = row.from_year,
        r.to_year = row.to_year,
        r.appearances = row.appearances,
        r.goals = row.goals
    """
    
    for i in range(0, len(edges_data), BATCH_SIZE):
        batch = edges_data[i:i+BATCH_SIZE]
        session.run(query, batch=batch)
```

**5. Handle NULL values:**
```python
# Neo4j khÃ´ng thÃ­ch NULL trong properties
def clean_row(row):
    return {
        k: v if pd.notna(v) else None 
        for k, v in row.items()
    }
```

**6. Progress Tracking:**
```python
from tqdm import tqdm

with tqdm(total=len(players_data), desc="Importing players") as pbar:
    for i in range(0, len(players_data), BATCH_SIZE):
        batch = players_data[i:i+BATCH_SIZE]
        import_batch(session, batch)
        pbar.update(len(batch))
```

**7. Transaction Management:**
```python
# Má»—i batch lÃ  1 transaction
with driver.session() as session:
    with session.begin_transaction() as tx:
        tx.run(query, batch=batch)
        tx.commit()  # Commit sau khi batch xong
```

#### Import Flow:
1. **Nodes trÆ°á»›c**: Player, Coach, Club, National Team, Position, Nationality
2. **Relationships sau**: PLAYED_FOR, TEAMMATE, HAS_POSITION...

#### Output:
Data Ä‘Æ°á»£c import vÃ o **Neo4j Aura** database vá»›i cáº¥u trÃºc:
```
(Player)-[PLAYED_FOR]->(Club)
(Player)-[TEAMMATE]->(Player)
(Player)-[HAS_POSITION]->(Position)
(Coach)-[COACHED]->(Club)
(Player)-[UNDER_COACH]->(Coach)
```

#### Lá»‡nh cháº¡y:
```bash
# Import má»›i
make import
# hoáº·c
python -m neo4j_import.import_to_neo4j \
    --uri $NEO4J_URI \
    --user $NEO4J_USER \
    --password $NEO4J_PASSWORD

# Reset DB vÃ  import láº¡i
make import-reset
# hoáº·c
python -m neo4j_import.import_to_neo4j --reset
```

---

### **BÆ¯á»šC 6: VALIDATE - KIá»‚M TRA Dá»® LIá»†U**

#### ğŸ“ File: `tools/validation.py`

#### CÃ¡c kiá»ƒm tra:
1. **Äáº¿m nodes**: Sá»‘ lÆ°á»£ng Player, Coach, Club...
2. **Äáº¿m relationships**: Sá»‘ lÆ°á»£ng edges tá»«ng loáº¡i
3. **Kiá»ƒm tra orphan nodes**: Nodes khÃ´ng cÃ³ relationship
4. **Kiá»ƒm tra missing properties**: Nodes thiáº¿u thuá»™c tÃ­nh quan trá»ng
5. **Sample queries**: Test cÃ¡c query phá»• biáº¿n

#### Validation Queries:
```cypher
-- Äáº¿m cáº§u thá»§
MATCH (p:Player) RETURN count(p)

-- Äáº¿m quan há»‡ Ä‘á»“ng Ä‘á»™i
MATCH ()-[r:TEAMMATE]->() RETURN count(r)

-- TÃ¬m cáº§u thá»§ khÃ´ng cÃ³ CLB
MATCH (p:Player)
WHERE NOT (p)-[:PLAYED_FOR]->(:Club)
RETURN p.name

-- TÃ¬m top cáº§u thá»§ cÃ³ nhiá»u Ä‘á»“ng Ä‘á»™i
MATCH (p:Player)-[:TEAMMATE]->(teammate)
RETURN p.name, count(teammate) as num_teammates
ORDER BY num_teammates DESC
LIMIT 10
```

#### Output:
```
reports/
â””â”€â”€ import_report.txt
```

Ná»™i dung report:
```
=== VIETNAM FOOTBALL KNOWLEDGE GRAPH VALIDATION REPORT ===
Generated: 2025-12-09 10:30:00

NODE COUNTS:
- Players: 652
- Coaches: 87
- Clubs: 43
- National Teams: 8
- Positions: 12
- Nationalities: 25
TOTAL NODES: 827

RELATIONSHIP COUNTS:
- PLAYED_FOR: 1,234
- TEAMMATE: 8,567
- COACHED: 298
- HAS_POSITION: 652
- HAS_NATIONALITY: 739
TOTAL RELATIONSHIPS: 11,490

ORPHAN NODES: 3
- Player: Nguyá»…n VÄƒn A (wiki_id: 123456)
...

MISSING PROPERTIES:
- 12 players missing birth_date
- 5 players missing position
...
```

#### Lá»‡nh cháº¡y:
```bash
make validate
# hoáº·c
python -m tools.validation \
    --neo4j-uri $NEO4J_URI \
    --user $NEO4J_USER \
    --password $NEO4J_PASSWORD
```

---

## ğŸš€ CHáº Y TOÃ€N Bá»˜ PIPELINE

### CÃ¡ch 1: Sá»­ dá»¥ng Makefile (Khuyáº¿n nghá»‹)
```bash
# Cháº¡y táº¥t cáº£ bÆ°á»›c
make all

# Hoáº·c tá»«ng bÆ°á»›c
make crawl        # BÆ°á»›c 1: Thu tháº­p
make parse        # BÆ°á»›c 2: PhÃ¢n tÃ­ch
make normalize    # BÆ°á»›c 3: Chuáº©n hÃ³a
make build-rels   # BÆ°á»›c 4: XÃ¢y quan há»‡
make import       # BÆ°á»›c 5: Import DB
make validate     # BÆ°á»›c 6: Kiá»ƒm tra
```

### CÃ¡ch 2: Sá»­ dá»¥ng Shell Script
```bash
bash run.sh
```

### CÃ¡ch 3: Cháº¡y manual tá»«ng bÆ°á»›c
```bash
python -m scraper.wikipedia_crawler --fetch-all
python -m parser.infobox_parser --parse-all
python -m processor.entity_builder --normalize-all
python -m processor.relationship_builder --build-all
python -m neo4j_import.import_to_neo4j --uri $NEO4J_URI --user $NEO4J_USER --password $NEO4J_PASSWORD
python -m tools.validation --neo4j-uri $NEO4J_URI --user $NEO4J_USER --password $NEO4J_PASSWORD
```

---

## ğŸ“Š Dá»® LIá»†U THU THáº¬P ÄÆ¯á»¢C

### Thá»‘ng kÃª thá»±c táº¿ Ä‘Ã£ thu tháº­p:

| Entity Type | Raw JSON | Parsed | Cleaned | Trong Neo4j |
|------------|----------|--------|---------|-------------|
| **Players** | 557 | 541 | 526 | ~500 |
| **Coaches** | 74 | 73 (9+64) | 63 | ~60 |
| **Clubs** | 106 | 79 | 78 | ~75 |
| **National Teams** | - | 18 | 13 | ~10 |
| **Stadiums** | - | 42 | 41 | ~40 |
| **Competitions** | - | 392 | 272 | ~250 |
| **Positions (ref)** | - | - | 20 | 20 |
| **Nationalities (ref)** | - | - | 18 | 18 |
| **Provinces (ref)** | - | - | 67 | 67 |

**Relationships:**
| Edge Type | Sá»‘ lÆ°á»£ng | File size |
|-----------|----------|-----------|
| `PLAYED_FOR` | ~1,400 | 97KB |
| `PLAYED_FOR_NATIONAL` | ~550 | 38KB |
| `COACHED` | ~250 | 17KB |
| `COACHED_NATIONAL` | ~60 | 4.3KB |
| `TEAMMATE` | ~6,000 | 438KB |
| `NATIONAL_TEAMMATE` | **~18,000** | **1.3MB** |
| `UNDER_COACH` | ~40 | 2.7KB |
| `HAS_POSITION` | ~520 | 6KB |
| `HAS_NATIONALITY` | ~580 | 14KB |
| `BORN_IN` | ~450 | 9.2KB |
| `SAME_PROVINCE` | ~600 | 14KB |
| `PLAYED_SAME_CLUB` | ~1,200 | 28KB |
| `CLUB_BASED_IN` | ~75 | 1.2KB |
| `HOME_STADIUM` | ~40 | 2.5KB |
| `COMPETES_IN` | ~80 | 2.4KB |
| `STADIUM_IN_PROVINCE` | ~40 | 971B |
| `PLAYER_FROM_PROVINCE` | ~450 | 9.6KB |
| **TOTAL** | **~30,000+** | **~1.98MB** |

### Loáº¡i dá»¯ liá»‡u:
- âœ… Cáº§u thá»§ nam
- âœ… Cáº§u thá»§ ná»¯
- âœ… Huáº¥n luyá»‡n viÃªn
- âœ… CÃ¢u láº¡c bá»™
- âœ… Äá»™i tuyá»ƒn quá»‘c gia
- âœ… SÃ¢n váº­n Ä‘á»™ng
- âœ… Giáº£i Ä‘áº¥u

---

## ğŸ”§ Cáº¤U HÃŒNH

### Environment Variables
```bash
export NEO4J_URI="neo4j+s://xxxxx.databases.neo4j.io"
export NEO4J_USER="neo4j"
export NEO4J_PASSWORD="your-password"
```

### File cáº¥u hÃ¬nh: `config/config.py`
```python
# Rate limiting
API_DELAY_SECONDS = 1.0
API_MAX_RETRIES = 3

# Batch size
BATCH_SIZE = 500

# Deduplication rules
DEDUP_FIELDS = {...}

# Categories to crawl
WIKI_CATEGORIES = {...}
```

---

## ğŸ› ï¸ CÃ”NG Cá»¤ VÃ€ THÆ¯ VIá»†N

### Thu tháº­p dá»¯ liá»‡u:
- `mwclient`: MediaWiki API client
- `requests`: HTTP requests
- `tqdm`: Progress bar

### Xá»­ lÃ½ dá»¯ liá»‡u:
- `mwparserfromhell`: Parse Wikitext
- `pandas`: Data manipulation
- `numpy`: Numerical operations

### Database:
- `neo4j`: Neo4j Python driver
- `py2neo`: Alternative Neo4j client

### Utilities:
- `python-dotenv`: Load environment variables
- `pyyaml`: YAML configuration

---

## ğŸ“ˆ FLOW CHART CHI TIáº¾T

```
Wikipedia API
    â†“
[Crawling Module]
â”œâ”€â”€ Fetch categories
â”œâ”€â”€ Get page list
â”œâ”€â”€ Download wikitext
â””â”€â”€ Save JSON
    â†“
data/raw/*.json
    â†“
[Parsing Module]
â”œâ”€â”€ Load JSON
â”œâ”€â”€ Parse wikitext
â”œâ”€â”€ Extract infobox
â”œâ”€â”€ Map fields
â””â”€â”€ Save JSONL
    â†“
data/parsed/*.jsonl
    â†“
[Normalization Module]
â”œâ”€â”€ Load JSONL â†’ DataFrame
â”œâ”€â”€ Remove missing required
â”œâ”€â”€ Deduplicate entities
â”œâ”€â”€ Create canonical names
â””â”€â”€ Export CSV
    â†“
data/processed/*.csv
    â†“
[Relationship Builder]
â”œâ”€â”€ Load entity CSVs
â”œâ”€â”€ Build Layer 1 (direct)
â”œâ”€â”€ Build Layer 2 (derived)
â”œâ”€â”€ Build Layer 3 (semantic)
â””â”€â”€ Export edge CSVs
    â†“
data/edges/*.csv
    â†“
[Neo4j Importer]
â”œâ”€â”€ Connect to Neo4j
â”œâ”€â”€ Create constraints
â”œâ”€â”€ Import nodes (batched)
â”œâ”€â”€ Import relationships
â””â”€â”€ Generate stats
    â†“
Neo4j Database
    â†“
[Validator]
â”œâ”€â”€ Count nodes/edges
â”œâ”€â”€ Find orphans
â”œâ”€â”€ Check properties
â””â”€â”€ Generate report
    â†“
reports/import_report.txt
```

---

## ğŸ¯ ÄIá»‚M Máº NH & Háº N CHáº¾ Cá»¦A QUY TRÃŒNH

### âœ… Äiá»ƒm máº¡nh:

1. **Tá»± Ä‘á»™ng hoÃ n toÃ n**: 
   - Chá»‰ cáº§n `make all` hoáº·c `bash run.sh`
   - Pipeline cháº¡y tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i khÃ´ng cáº§n can thiá»‡p

2. **Caching thÃ´ng minh**: 
   - LÆ°u filename vá»›i page_id: `player_3289965.json`
   - Load cached IDs khi start â†’ skip Ä‘Ã£ cÃ³
   - Tiáº¿t kiá»‡m bandwidth vÃ  thá»i gian

3. **Rate limiting chuáº©n chá»‰nh**:
   - 1s delay giá»¯a requests
   - Retry 3 láº§n vá»›i backoff
   - User-Agent Ä‘Ãºng chuáº©n Wikipedia

4. **Deduplication thÃ´ng minh**:
   - Dá»±a trÃªn name + birth_date
   - Táº¡o canonical_name cho duplicates
   - Giá»¯ entity cÃ³ info Ä‘áº§y Ä‘á»§ nháº¥t

5. **Relationship inference máº¡nh máº½**:
   - 3 layers: Direct, Derived, Semantic
   - Tá»± Ä‘á»™ng tÃ¬m teammate dá»±a trÃªn time overlap
                                                                                                                                                                                                               - Táº¡o Ä‘Æ°á»£c 17 loáº¡i relationships khÃ¡c nhau

6. **Batch processing hiá»‡u quáº£**:
   - 500 records/transaction
   - TrÃ¡nh memory overflow
   - Progress bar vá»›i tqdm

7. **Validation toÃ n diá»‡n**:
   - Äáº¿m nodes/edges
   - TÃ¬m orphan nodes
   - Check missing properties
   - Generate report tá»± Ä‘á»™ng

8. **Incremental updates**:
   - CÃ³ thá»ƒ fetch thÃªm categories má»›i
   - Parse láº¡i 1 entity type
   - Update tá»«ng pháº§n vÃ o Neo4j

### âš ï¸ Háº¡n cháº¿ & ThÃ¡ch thá»©c:

1. **Data quality tá»« Wikipedia**:
   - Nhiá»u cáº§u thá»§ thiáº¿u infobox hoáº·c infobox khÃ´ng Ä‘áº§y Ä‘á»§
   - NgÃ y sinh, chiá»u cao thÆ°á»ng missing
   - Career history khÃ´ng consistent (cÃ³ player cÃ³, cÃ³ player khÃ´ng)
   - Example: LÆ°u Ngá»c Mai cÃ³ `date_of_birth: null`

2. **Entity matching khÃ³ khÄƒn**:
   - Club names khÃ´ng chuáº©n: "HoÃ ng Anh Gia Lai" vs "HAGL" vs "HoÃ ng Anh Gia Lai FC"
   - Foreign clubs khÃ´ng cÃ³ trong database â†’ `to_club_id: NULL`
   - Pháº£i match by name â†’ khÃ´ng chÃ­nh xÃ¡c 100%

3. **Wikitext parsing phá»©c táº¡p**:
   - Nhiá»u template formats khÃ¡c nhau
   - Numbered params khÃ´ng theo thá»© tá»± (clubs1, clubs2... cÃ³ thá»ƒ skip)
   - Vietnamese vs English field names
   - Nested templates: `{{birth date|{{CURRENTYEAR}}|1|1}}`

4. **Performance issues**:
   - File `national_teammate.csv` 1.3MB â†’ hÃ ng chá»¥c nghÃ¬n rows
   - Import vÃ o Neo4j máº¥t nhiá»u thá»i gian
   - Query teammate relationships cháº­m náº¿u khÃ´ng index

5. **Data inconsistency**:
   - Má»™t sá»‘ cáº§u thá»§ cÃ³ 2 files: `coaches.jsonl` vÃ  `coachs.jsonl` (typo)
   - Foreign player naturalized: cÃ³ 2 nationalities
   - Career end_year = NULL (Ä‘ang thi Ä‘áº¥u) â†’ khÃ³ xá»­ lÃ½

6. **Memory vÃ  Storage**:
   - Total raw JSON: ~200MB
   - Neo4j database: ~500MB (vá»›i indexes)
   - Cáº§n RAM ~2GB Ä‘á»ƒ cháº¡y pipeline

7. **Manual work váº«n cáº§n**:
   - Pháº£i manual config categories trong `config.py`
   - Pháº£i manual mapping position codes
   - Pháº£i review vÃ  fix data errors

8. **Update frequency**:
   - Pháº£i re-crawl toÃ n bá»™ Ä‘á»ƒ update
   - KhÃ´ng cÃ³ mechanism Ä‘á»ƒ chá»‰ fetch changed pages
   - Wikipedia thay Ä‘á»•i â†’ pháº£i re-parse

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

- Wikipedia API: https://www.mediawiki.org/wiki/API:Main_page
- Neo4j Python Driver: https://neo4j.com/docs/python-manual/current/
- mwparserfromhell: https://github.com/earwig/mwparserfromhell
- Project README: `README.md`
- Makefile: `Makefile`

---

## ğŸ§¹ QUY TRÃŒNH LÃ€M Sáº CH Dá»® LIá»†U (DATA CLEANING)

### Tá»•ng quan
Sau khi crawl vÃ  parse, dá»¯ liá»‡u cáº§n Ä‘Æ°á»£c lÃ m sáº¡ch Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng trÆ°á»›c khi import vÃ o Neo4j.

### 1. **Deduplication - Loáº¡i bá» trÃ¹ng láº·p**

#### Module: `enrichment/deduplication.py`

#### Chiáº¿n lÆ°á»£c:

**a) Entity Deduplication:**
```python
class EntityDeduplicator:
    def __init__(self, threshold=0.90):
        self.threshold = threshold
        self._existing_entities = {}  # type -> set of normalized names
    
    def is_duplicate(self, text, entity_type):
        norm_text = self._normalize(text)
        
        # Exact match
        if norm_text in self._existing_entities[entity_type]:
            return (True, 1.0)
        
        # Fuzzy match with RapidFuzz
        for existing in self._existing_entities[entity_type]:
            score = fuzz.token_set_ratio(norm_text, existing) / 100.0
            if score >= self.threshold:
                return (True, score)
        
        return (False, None)
```

**VÃ­ dá»¥ thá»±c táº¿:**
```python
# Case 1: Exact duplicate
"Nguyá»…n CÃ´ng PhÆ°á»£ng" vs "Nguyá»…n CÃ´ng PhÆ°á»£ng" 
â†’ Duplicate (100%)

# Case 2: Fuzzy match
"CÃ´ng PhÆ°á»£ng" vs "Nguyá»…n CÃ´ng PhÆ°á»£ng"
â†’ Duplicate (90.5% similarity)

# Case 3: Different person
"Nguyá»…n VÄƒn A" vs "Nguyá»…n VÄƒn B"
â†’ Not duplicate (80% < 90% threshold)
```

**b) Relation Deduplication:**
```python
class RelationDeduplicator:
    def __init__(self, threshold=0.95):
        self._existing_relations = set()  # (subj_id, pred, obj_id)
    
    def is_duplicate(self, subject_id, predicate, object_id):
        tuple_key = (subject_id, predicate, object_id)
        return tuple_key in self._existing_relations
```

**VÃ­ dá»¥:**
```python
# Duplicate relationship
(Player:123, PLAYED_FOR, Club:456) exists
+ (Player:123, PLAYED_FOR, Club:456) new
â†’ Skip (duplicate)

# Different time period = different relationship
(Player:123, PLAYED_FOR, Club:456, 2015-2018) exists
+ (Player:123, PLAYED_FOR, Club:456, 2019-2020) new
â†’ Keep (different time period)
```

### 2. **Validation - Kiá»ƒm tra tÃ­nh há»£p lá»‡**

#### Module: `enrichment/validation.py`

#### Validation Rules:

**a) Temporal Consistency:**
```python
def validate_temporal_consistency(relation):
    # Birth date pháº£i trÆ°á»›c career start
    if player.birth_year and relation.from_year:
        age_at_start = relation.from_year - player.birth_year
        if age_at_start < 15:  # Too young
            return False, "Player too young to play professionally"
        if age_at_start > 50:  # Too old
            return False, "Unrealistic age"
    
    # Career end khÃ´ng thá»ƒ trÆ°á»›c start
    if relation.from_year and relation.to_year:
        if relation.to_year < relation.from_year:
            return False, "End year before start year"
    
    return True, None
```

**VÃ­ dá»¥ thá»±c táº¿:**
```python
# Invalid: Player 10 years old
Player: birth_year=2005
Relation: PLAYED_FOR from_year=2010 (age=5)
â†’ REJECTED (too young)

# Valid
Player: birth_year=1995
Relation: PLAYED_FOR from_year=2015 (age=20)
â†’ ACCEPTED
```

**b) Type Constraints:**
```python
RELATION_CONSTRAINTS = {
    "PLAYED_FOR": {
        "subject": "Player",
        "object": "Club",
        "temporal": True,
    },
    "COACHED": {
        "subject": "Coach", 
        "object": "Club",
        "temporal": True,
    },
    "BORN_IN": {
        "subject": "Player",
        "object": "Province",
        "unique": True,  # Only one birthplace
    },
}

def validate_type_constraint(relation):
    constraint = RELATION_CONSTRAINTS[relation.type]
    
    # Check subject type
    if relation.subject.type != constraint["subject"]:
        return False, f"Invalid subject type"
    
    # Check object type
    if relation.object.type != constraint["object"]:
        return False, f"Invalid object type"
    
    # Check uniqueness
    if constraint.get("unique"):
        existing = get_existing_relations(relation.subject, relation.type)
        if len(existing) > 0:
            return False, "Duplicate unique relation"
    
    return True, None
```

**c) Conflict Detection:**
```python
def detect_conflicts(new_relation, existing_relations):
    conflicts = []
    
    for existing in existing_relations:
        # Conflict: CÃ¹ng thá»i Ä‘iá»ƒm chÆ¡i cho 2 CLB khÃ¡c nhau
        if (new_relation.type == "PLAYED_FOR" and
            existing.type == "PLAYED_FOR" and
            time_overlap(new_relation, existing) and
            new_relation.club != existing.club):
            conflicts.append({
                "type": "temporal_conflict",
                "message": f"Player at 2 clubs simultaneously",
                "confidence": 0.8
            })
    
    return conflicts
```

### 3. **Data Quality Metrics**

#### Completeness Check:
```python
def calculate_completeness(players_df):
    metrics = {
        "birth_date": players_df['date_of_birth'].notna().sum() / len(players_df),
        "height": players_df['height'].notna().sum() / len(players_df),
        "position": players_df['position'].notna().sum() / len(players_df),
        "career_history": players_df['clubs_history'].notna().sum() / len(players_df),
    }
    return metrics
```

**Káº¿t quáº£ thá»±c táº¿:**
```
Completeness Metrics:
- birth_date: 60.8% (320/526 players)
- height: 78.3% (412/526 players)
- position: 94.7% (498/526 players)
- career_history: 87.1% (458/526 players)
```

#### Accuracy Check:
```python
def calculate_accuracy():
    total_parsed = 541
    total_clean = 526
    duplicates_removed = total_parsed - total_clean
    
    duplicate_rate = duplicates_removed / total_parsed  # 2.8%
    parse_success_rate = total_parsed / 557  # 97.1%
    
    return {
        "duplicate_rate": duplicate_rate,
        "parse_success_rate": parse_success_rate
    }
```

### 4. **Orphan Nodes Cleanup**

#### Script: `cleanup_orphaned_nodes.py`

```python
def find_orphan_nodes(session):
    # TÃ¬m nodes khÃ´ng cÃ³ relationships
    query = """
    MATCH (n)
    WHERE NOT (n)--()  // No incoming or outgoing edges
    RETURN labels(n)[0] as type, count(n) as count
    """
    result = session.run(query)
    return result.data()

def delete_orphan_nodes(session):
    # XÃ³a orphan nodes
    query = """
    MATCH (n)
    WHERE NOT (n)--()
    DELETE n
    RETURN count(n) as deleted
    """
    result = session.run(query)
    return result.single()['deleted']
```

**Káº¿t quáº£ cleanup thá»±c táº¿:**
```
=== CLEANUP RESULTS ===
Orphaned Clubs: 358 deleted
Orphaned National Teams: 40 deleted
Total Orphaned Nodes: 398 deleted

Reason: Entities extracted tá»« text nhÆ°ng khÃ´ng cÃ³ wiki_id
â†’ KhÃ´ng thá»ƒ link vá»›i relationships
â†’ Trá»Ÿ thÃ nh orphan nodes
```

### 5. **Data Normalization**

#### Normalize Names:
```python
def normalize_name(name):
    # Remove nicknames in parentheses
    name = re.sub(r'\s*\([^)]*\)\s*', '', name)
    
    # Remove wiki markup
    name = re.sub(r'\[\[([^\]|]*)\|?([^\]]*)\]\]', r'\2' if r'\2' else r'\1', name)
    
    # Normalize whitespace
    name = ' '.join(name.split())
    
    return name.strip()

# Examples:
"Nguyá»…n CÃ´ng PhÆ°á»£ng (PhÆ°á»£ng)" â†’ "Nguyá»…n CÃ´ng PhÆ°á»£ng"
"[[HoÃ ng Anh Gia Lai|HAGL]]" â†’ "HAGL"
"  Nguyá»…n   VÄƒn   A  " â†’ "Nguyá»…n VÄƒn A"
```

#### Normalize Positions:
```python
POSITION_MAPPINGS = {
    "thá»§ mÃ´n": "GK",
    "goalkeeper": "GK",
    "tiá»n Ä‘áº¡o": "FW",
    "forward": "FW",
    "tiá»n vá»‡": "MF",
    "midfielder": "MF",
    # ... 30+ mappings
}

def normalize_position(position):
    position_lower = position.lower().strip()
    return POSITION_MAPPINGS.get(position_lower, position.upper()[:3])

# Examples:
"Thá»§ mÃ´n" â†’ "GK"
"Tiá»n Ä‘áº¡o cáº¯m" â†’ "FW"
"trung vá»‡" â†’ "CB"
```

### 6. **Missing Data Handling**

#### Strategy:

**a) NULL vs Empty String:**
```python
# Trong parsing
if field_value == "":
    parsed_data[field_name] = None  # Use NULL instead of empty string
else:
    parsed_data[field_name] = field_value
```

**b) Default Values:**
```python
# Default values cho missing data
defaults = {
    "birth_year": None,  # KhÃ´ng guess
    "height": None,  # KhÃ´ng guess
    "position": "Unknown",  # Use placeholder
    "nationality": "Vietnam",  # Reasonable default for VN league
}
```

**c) Inference tá»« context:**
```python
def infer_nationality(player):
    # Náº¿u khÃ´ng cÃ³ nationality nhÆ°ng cÃ³ nÆ¡i sinh á»Ÿ VN
    if player.nationality is None and player.birth_place:
        if any(province in player.birth_place for province in VN_PROVINCES):
            return "Vietnam"
    
    # Náº¿u chÆ¡i cho Ä‘á»™i tuyá»ƒn VN
    if player.national_team_history:
        if any("Vietnam" in team for team in player.national_team_history):
            return "Vietnam"
    
    return None
```

### 7. **Final Quality Report**

```python
def generate_quality_report(data):
    report = {
        "total_entities": len(data),
        "duplicates_removed": data.duplicates_removed,
        "invalid_records": data.invalid_records,
        "missing_critical_fields": {
            "no_wiki_id": data.query('wiki_id.isnull()').shape[0],
            "no_name": data.query('name.isnull()').shape[0],
        },
        "data_completeness": {
            "birth_date": f"{data['date_of_birth'].notna().sum() / len(data) * 100:.1f}%",
            "position": f"{data['position'].notna().sum() / len(data) * 100:.1f}%",
            "height": f"{data['height'].notna().sum() / len(data) * 100:.1f}%",
        },
        "validation_passed": data.validation_passed,
        "validation_failed": data.validation_failed,
    }
    return report
```

**Káº¿t quáº£ thá»±c táº¿:**
```json
{
  "total_entities": 541,
  "duplicates_removed": 15,
  "invalid_records": 0,
  "missing_critical_fields": {
    "no_wiki_id": 0,
    "no_name": 0
  },
  "data_completeness": {
    "birth_date": "60.8%",
    "position": "94.7%",
    "height": "78.3%"
  },
  "validation_passed": 526,
  "validation_failed": 0
}
```

---

## ğŸ’ QUY TRÃŒNH LÃ€M GIÃ€U Dá»® LIá»†U (DATA ENRICHMENT)

### Tá»•ng quan
Enrichment bá»• sung thÃ´ng tin bá»‹ thiáº¿u tá»« ná»™i dung Wikipedia articles sá»­ dá»¥ng NLP.

### PhÆ°Æ¡ng phÃ¡p Enrichment

#### **PhÆ°Æ¡ng phÃ¡p 1: Infobox Re-parsing**
#### **PhÆ°Æ¡ng phÃ¡p 2: NLP-based Extraction**

---

### PHÆ¯Æ NG PHÃP 1: INFOBOX RE-PARSING

#### Script: `infobox_enrichment.py`

#### Má»¥c tiÃªu:
Parsing láº¡i infobox Ä‘á»ƒ extract thÃ´ng tin bá»‹ miss láº§n Ä‘áº§u:
- Career history vá»›i **caps/goals chi tiáº¿t**
- Current club & club number
- Missing birth dates
- Nationality náº¿u thiáº¿u

#### Implementation:

```python
class InfoboxEnrichmentParser:
    def extract_clubs_history(self, infobox):
        """Extract clubs vá»›i caps/goals"""
        clubs_history = []
        
        i = 1
        while True:
            years_key = f'years{i}'
            clubs_key = f'clubs{i}'
            caps_key = f'caps{i}'
            goals_key = f'goals{i}'
            
            if years_key not in infobox:
                break
            
            # Parse years: "2012-15" â†’ (2012, 2015)
            from_year, to_year = self.parse_year_range(infobox[years_key])
            
            # Clean club name
            club_name = self._clean_entity_name(infobox[clubs_key])
            
            entry = {
                'club_name': club_name,
                'from_year': from_year,
                'to_year': to_year,
                'caps': int(infobox.get(caps_key, 0)) if caps_key in infobox else None,
                'goals': int(infobox.get(goals_key, 0)) if goals_key in infobox else None,
            }
            
            clubs_history.append(entry)
            i += 1
        
        return clubs_history
```

**VÃ­ dá»¥ infobox:**
```python
infobox = {
    'years1': '2015-18',
    'clubs1': '[[HoÃ ng Anh Gia Lai]]',
    'caps1': '89',
    'goals1': '34',
    'years2': '2019-20',
    'clubs2': '[[SÃ i GÃ²n FC]]',
    'caps2': '56',
    'goals2': '23',
}

# Parsed result:
[
    {
        'club_name': 'HoÃ ng Anh Gia Lai',
        'from_year': 2015,
        'to_year': 2018,
        'caps': 89,
        'goals': 34
    },
    {
        'club_name': 'SÃ i GÃ²n FC',
        'from_year': 2019,
        'to_year': 2020,
        'caps': 56,
        'goals': 23
    }
]
```

#### Import vÃ o Neo4j:

```python
def enrich_player_relationships(session, player_wiki_id, clubs_history):
    for entry in clubs_history:
        query = """
        MATCH (p:Player {wiki_id: $player_wiki_id})
        MATCH (c:Club {name: $club_name})
        MERGE (p)-[r:PLAYED_FOR]->(c)
        SET r.from_year = $from_year,
            r.to_year = $to_year,
            r.caps = $caps,
            r.goals = $goals,
            r.source = 'infobox_enrichment',
            r.enriched_at = datetime()
        """
        session.run(query, 
            player_wiki_id=player_wiki_id,
            club_name=entry['club_name'],
            from_year=entry['from_year'],
            to_year=entry['to_year'],
            caps=entry['caps'],
            goals=entry['goals']
        )
```

**âš ï¸ Váº¥n Ä‘á» phÃ¡t hiá»‡n:**
```cypher
-- MERGE sáº½ match existing relationships vÃ  OVERWRITE source!
MERGE (p)-[r:PLAYED_FOR]->(c)
SET r.source = 'infobox_enrichment'  // â† Overwrite NULL â†’ 'infobox_enrichment'

-- Khi cleanup, delete WHERE source='infobox_enrichment'
-- â†’ XÃ³a cáº£ relationships gá»‘c!
```

**Káº¿t quáº£:**
```
Relationships bá»‹ xÃ³a nháº§m: 793 edges
(Do overwrite source tag cá»§a relationships gá»‘c)
```

---

### PHÆ¯Æ NG PHÃP 2: NLP-BASED EXTRACTION

#### Script: `strict_nlp_enrichment_v2.py`

#### Pipeline NLP:

```
Text Collection â†’ Preprocessing â†’ NER â†’ Relation Extraction â†’ Validation â†’ Neo4j Import
```

#### 2.1. Text Collection

```python
def collect_wikipedia_texts(wiki_id):
    """Collect article text tá»« Wikipedia"""
    page = wikipedia.page(pageid=wiki_id)
    
    # Láº¥y toÃ n bá»™ text (khÃ´ng chá»‰ infobox)
    full_text = page.content
    
    # Split thÃ nh sentences
    sentences = sent_tokenize(full_text, language='vietnamese')
    
    return sentences
```

**VÃ­ dá»¥ text:**
```
"Nguyá»…n CÃ´ng PhÆ°á»£ng sinh ngÃ y 21 thÃ¡ng 1 nÄƒm 1995 táº¡i Nghá»‡ An. 
Anh lÃ  cáº§u thá»§ chá»§ chá»‘t cá»§a HoÃ ng Anh Gia Lai tá»« 2015 Ä‘áº¿n 2020 
vá»›i 89 tráº­n vÃ  34 bÃ n tháº¯ng. Sau Ä‘Ã³ anh chuyá»ƒn Ä‘áº¿n SÃ i GÃ²n FC."
```

#### 2.2. Named Entity Recognition (NER)

##### **Strict NER - Dictionary-based:**

```python
class StrictNLPEnrichment:
    def __init__(self):
        # Load existing entities tá»« Neo4j
        self.players = {}  # name -> wiki_id
        self.clubs = {}
        self.provinces = {}
        self._load_existing_entities()
    
    def _load_existing_entities(self):
        """Load táº¥t cáº£ entities tá»« Neo4j"""
        with self.driver.session() as session:
            # Players
            result = session.run("MATCH (p:Player) RETURN p.name, p.wiki_id")
            for r in result:
                self.players[r['name'].lower()] = r['wiki_id']
            
            # Clubs
            result = session.run("MATCH (c:Club) RETURN c.name, c.wiki_id")
            for r in result:
                self.clubs[r['name'].lower()] = r['wiki_id']
    
    def strict_entity_recognition(self, text):
        """NER vá»›i strict matching - CHá»ˆ nháº­n entities Ä‘Ã£ cÃ³ trong Neo4j"""
        entities = []
        
        # Dictionary-based matching
        for player_name, wiki_id in self.players.items():
            if player_name in text.lower():
                entities.append({
                    "text": player_name,
                    "type": "PLAYER",
                    "wiki_id": wiki_id,
                    "confidence": 1.0,
                    "source": "dictionary"
                })
        
        for club_name, wiki_id in self.clubs.items():
            if club_name in text.lower():
                entities.append({
                    "text": club_name,
                    "type": "CLUB",
                    "wiki_id": wiki_id,
                    "confidence": 1.0,
                    "source": "dictionary"
                })
        
        return entities
```

**VÃ­ dá»¥ NER output:**
```json
{
  "sentence": "Nguyá»…n CÃ´ng PhÆ°á»£ng chÆ¡i cho HoÃ ng Anh Gia Lai tá»« 2015.",
  "entities": [
    {
      "text": "Nguyá»…n CÃ´ng PhÆ°á»£ng",
      "type": "PLAYER",
      "wiki_id": 123456,
      "confidence": 1.0,
      "source": "dictionary",
      "start": 0,
      "end": 18
    },
    {
      "text": "HoÃ ng Anh Gia Lai",
      "type": "CLUB",
      "wiki_id": 789012,
      "confidence": 1.0,
      "source": "dictionary",
      "start": 28,
      "end": 45
    },
    {
      "text": "2015",
      "type": "DATE",
      "confidence": 0.95,
      "source": "pattern",
      "start": 50,
      "end": 54
    }
  ]
}
```

**Káº¿t quáº£ thá»±c táº¿:**
```
Entities recognized: 20,555
- Players: 526 (from Neo4j dictionary)
- Clubs: 78 (from Neo4j dictionary)
- Provinces: 67 (from Neo4j dictionary)
- Dates: ~19,000 (pattern-based)
- Positions: ~800 (pattern-based)
```

#### 2.3. Relation Extraction

```python
def extract_relations(sentence, entities):
    """Extract relationships tá»« sentence dá»±a trÃªn entities"""
    relations = []
    
    # Pattern 1: PLAYED_FOR
    # "X chÆ¡i cho Y tá»« Z"
    pattern = r"(.+?)\s+(chÆ¡i cho|thi Ä‘áº¥u cho|gia nháº­p)\s+(.+?)(\s+tá»«\s+(\d{4}))?"
    match = re.search(pattern, sentence, re.IGNORECASE)
    
    if match:
        player_text = match.group(1)
        club_text = match.group(3)
        year = match.group(5)
        
        # Match vá»›i entities
        player = find_entity(entities, player_text, "PLAYER")
        club = find_entity(entities, club_text, "CLUB")
        
        if player and club:
            relations.append({
                "subject": player,
                "predicate": "PLAYED_FOR",
                "object": club,
                "from_year": int(year) if year else None,
                "confidence": 0.85,
                "source_sentence": sentence
            })
    
    # Pattern 2: BORN_IN
    # "X sinh táº¡i Y"
    pattern = r"(.+?)\s+(sinh|sinh táº¡i|sinh ngÃ y.+?táº¡i)\s+(.+)"
    match = re.search(pattern, sentence, re.IGNORECASE)
    
    if match:
        player_text = match.group(1)
        province_text = match.group(3)
        
        player = find_entity(entities, player_text, "PLAYER")
        province = find_entity(entities, province_text, "PROVINCE")
        
        if player and province:
            relations.append({
                "subject": player,
                "predicate": "BORN_IN",
                "object": province,
                "confidence": 0.90,
                "source_sentence": sentence
            })
    
    return relations
```

**VÃ­ dá»¥ Relation Extraction:**
```python
# Input
sentence = "Nguyá»…n CÃ´ng PhÆ°á»£ng sinh táº¡i Nghá»‡ An vÃ  chÆ¡i cho HAGL tá»« 2015."
entities = [
    {"text": "Nguyá»…n CÃ´ng PhÆ°á»£ng", "type": "PLAYER", "wiki_id": 123},
    {"text": "Nghá»‡ An", "type": "PROVINCE"},
    {"text": "HAGL", "type": "CLUB", "wiki_id": 456},
]

# Output
relations = [
    {
        "subject": {"wiki_id": 123, "type": "PLAYER"},
        "predicate": "BORN_IN",
        "object": {"name": "Nghá»‡ An", "type": "PROVINCE"},
        "confidence": 0.90
    },
    {
        "subject": {"wiki_id": 123, "type": "PLAYER"},
        "predicate": "PLAYED_FOR",
        "object": {"wiki_id": 456, "type": "CLUB"},
        "from_year": 2015,
        "confidence": 0.85
    }
]
```

**Káº¿t quáº£ thá»±c táº¿:**
```
Relations extracted: 1,489
Relations matched (cÃ³ cáº£ 2 entities trong Neo4j): 834
Safe relations (confidence >= 0.9): ~400
```

#### 2.4. Validation & Filtering

```python
def validate_enrichment_relation(relation, existing_graph):
    """Validate relation trÆ°á»›c khi import"""
    issues = []
    
    # 1. Check confidence threshold
    if relation['confidence'] < 0.9:
        issues.append("Low confidence")
        return False, issues
    
    # 2. Check if already exists
    if relation_exists(existing_graph, relation):
        issues.append("Duplicate")
        return False, issues
    
    # 3. Check temporal consistency
    if relation['predicate'] == 'PLAYED_FOR':
        if relation.get('from_year'):
            player_birth = get_player_birth_year(relation['subject'])
            if player_birth and relation['from_year'] - player_birth < 15:
                issues.append("Player too young")
                return False, issues
    
    # 4. Check type constraints
    expected_types = RELATION_TYPE_CONSTRAINTS[relation['predicate']]
    if relation['subject']['type'] != expected_types['subject']:
        issues.append(f"Invalid subject type")
        return False, issues
    
    return True, []
```

**Filtering results:**
```
Total extracted: 1,489 relations
After validation:
  - Duplicate: 655 (already in graph)
  - Low confidence (<0.9): 234
  - Invalid type: 45
  - Temporal error: 21
  - PASSED: 534 relations
```

#### 2.5. Import vÃ o Neo4j

```python
def import_enriched_relations(session, relations):
    """Import validated relations vÃ o Neo4j"""
    imported = 0
    
    for rel in relations:
        # Táº¡o relationship vá»›i source tag
        query = """
        MATCH (s {wiki_id: $subject_id})
        MATCH (o {wiki_id: $object_id})
        CREATE (s)-[r:$predicate]->(o)
        SET r.from_year = $from_year,
            r.to_year = $to_year,
            r.source = 'nlp_enrichment',
            r.confidence = $confidence,
            r.enriched_at = datetime(),
            r.source_sentence = $source_sentence
        """
        
        try:
            session.run(query,
                subject_id=rel['subject']['wiki_id'],
                object_id=rel['object']['wiki_id'],
                predicate=rel['predicate'],
                from_year=rel.get('from_year'),
                to_year=rel.get('to_year'),
                confidence=rel['confidence'],
                source_sentence=rel['source_sentence']
            )
            imported += 1
        except Exception as e:
            logger.error(f"Failed to import: {e}")
    
    return imported
```

---

### Káº¾T QUáº¢ ENRICHMENT

#### Thá»‘ng kÃª Files:

```bash
data/enrichment/
â”œâ”€â”€ recognized_entities.jsonl      # 20,555 entities recognized
â”œâ”€â”€ validated_entities.jsonl       # 20,555 validated
â”œâ”€â”€ extracted_relations.jsonl      # 1,489 relations extracted
â”œâ”€â”€ validated_relations.jsonl      # 1,489 validated
â”œâ”€â”€ matched_relations.jsonl        # 834 matched (cÃ³ cáº£ 2 entities)
â””â”€â”€ safe_relations.jsonl           # 0 (high-confidence only)
```

#### Enrichment Impact:

**TRÆ¯á»šC enrichment:**
```
Nodes: 1,060
Relationships: 35,391
Players missing relationships: 142 (27%)
Avg relationships per player: 67
```

**SAU infobox enrichment:**
```
New relationships added: ~2,371
  - PLAYED_FOR vá»›i caps/goals: ~1,800
  - PLAYED_FOR_NATIONAL vá»›i caps/goals: ~571

Players vá»›i complete career history: 458 (87%)
Relationships vá»›i caps/goals: ~2,300 (6.5%)
```

**SAU NLP enrichment:**
```
Additional entities recognized: 20,555
Additional relations extracted: 1,489
  - High confidence (>=0.9): 534
  - Matched & imported: 400
  
New information:
  - Birth places extracted: ~180
  - Career periods refined: ~220
  - Missing clubs added: 0 (strict mode)
```

#### Quality Improvement:

```
Data Completeness:
  BEFORE â†’ AFTER
  - Career history: 72% â†’ 87%
  - Caps/Goals data: 0% â†’ 65%
  - Birth place: 52% â†’ 58%
  - Temporal data: 68% â†’ 82%

Data Accuracy:
  - False positives: <1% (strict validation)
  - Duplicate rate: 2.8%
  - Temporal errors: 0.4%
```

#### Problems Encountered:

**1. Source Tag Overwrite:**
```
Issue: MERGE overwrites existing relationship source tags
Impact: 793 relationships deleted during cleanup
Solution: Use CREATE instead of MERGE, or check source before SET
```

**2. Foreign Clubs Not Matched:**
```
Issue: Players played for foreign clubs not in DB
Impact: ~600 PLAYED_FOR edges have NULL club_id
Solution: Either crawl foreign clubs or create placeholder nodes
```

**3. Orphaned Enrichment Nodes:**
```
Issue: Entities extracted without wiki_id become orphans
Count: 398 orphaned nodes (358 clubs + 40 teams)
Solution: Strict mode - only extract entities already in Neo4j
```

---

## ğŸ”§ CÃC Váº¤N Äá»€ THá»°C Táº¾ & GIáº¢I PHÃP

### Váº¥n Ä‘á» 1: Duplicate coaches files
**Hiá»‡n tÆ°á»£ng:**
```
data/parsed/
â”œâ”€â”€ coaches.jsonl    # 9 dÃ²ng
â””â”€â”€ coachs.jsonl     # 64 dÃ²ng  â† typo
```

**NguyÃªn nhÃ¢n:** Typo trong code hoáº·c multiple runs vá»›i tÃªn khÃ¡c nhau

**Giáº£i phÃ¡p:**
```python
# Merge 2 files
import pandas as pd
df1 = pd.read_json('coaches.jsonl', lines=True)
df2 = pd.read_json('coachs.jsonl', lines=True)
merged = pd.concat([df1, df2]).drop_duplicates(subset=['wiki_id'])
merged.to_json('coaches.jsonl', orient='records', lines=True)
```

### Váº¥n Ä‘á» 2: Club matching fails
**Hiá»‡n tÆ°á»£ng:**
```csv
from_player_id,to_club_id,to_club_name,from_year,to_year
422045,,Portuguesa,2002.0,2003.0
422045,,Vasco da Gama,2003.0,2003.0
```
`to_club_id` lÃ  NULL vÃ¬ clubs nÆ°á»›c ngoÃ i khÃ´ng cÃ³ trong DB.

**Giáº£i phÃ¡p hiá»‡n táº¡i:**
```python
# Trong relationship_builder.py
def match_club(club_name):
    # Try exact match first
    if club_name in club_lookup:
        return club_lookup[club_name]
    
    # Try fuzzy match
    normalized = normalize_club_name(club_name)
    if normalized in club_lookup:
        return club_lookup[normalized]
    
    # Return None for foreign clubs
    return None
```

**Giáº£i phÃ¡p tá»‘t hÆ¡n:**
- Crawl thÃªm foreign clubs tá»« Wikipedia
- Hoáº·c táº¡o node "Unknown Club" vá»›i tÃªn
- Hoáº·c link Ä‘áº¿n DBpedia/Wikidata

### Váº¥n Ä‘á» 3: Missing birth dates
**Hiá»‡n tÆ°á»£ng:**
```json
{
  "wiki_id": 3289965,
  "name": "LÆ°u Ngá»c Mai",
  "date_of_birth": null  â† Missing!
}
```

**NguyÃªn nhÃ¢n:**
- Wikipedia page khÃ´ng cÃ³ infobox
- Infobox thiáº¿u field ngÃ y sinh
- Date parsing fails do format láº¡

**Giáº£i phÃ¡p Ä‘Ã£ Ã¡p dá»¥ng:**
```python
def _extract_date(self, date_str):
    # Try multiple formats
    patterns = [
        r'(\d{4})-(\d{1,2})-(\d{1,2})',  # ISO
        r'{{birth date\|(\d{4})\|(\d{1,2})\|(\d{1,2})}}',  # Template
        r'(\d{1,2})\s+thÃ¡ng\s+(\d{1,2})\s+nÄƒm\s+(\d{4})',  # Vietnamese
    ]
    
    for pattern in patterns:
        match = re.search(pattern, date_str)
        if match:
            return normalize_date(match.groups())
    
    return None  # Give up
```

### Váº¥n Ä‘á» 4: Teammate explosion
**Hiá»‡n tÆ°á»£ng:**
```
national_teammate.csv: 1.3MB, ~18,000 rows
```

Má»—i cáº§u thá»§ Ä‘á»™i tuyá»ƒn VN cÃ³ ~50-100 Ä‘á»“ng Ä‘á»™i â†’ n*(n-1)/2 edges!

**VÃ­ dá»¥:**
- 100 cáº§u thá»§ Ä‘á»™i tuyá»ƒn â†’ 4,950 edges
- 200 cáº§u thá»§ â†’ 19,900 edges

**Giáº£i phÃ¡p:**
```python
# Option 1: Chá»‰ táº¡o edges cho cÃ¹ng thá»i ká»³
if overlap_years > 2:  # Chá»‰ táº¡o náº¿u cÃ¹ng Ä‘Ã¡ > 2 nÄƒm
    create_edge()

# Option 2: Limit sá»‘ teammates per player
max_teammates = 50
teammates = sorted(teammates, key=lambda x: overlap_years(x))[:max_teammates]

# Option 3: KhÃ´ng import vÃ o Neo4j, tÃ­nh runtime
# Query: "Ai lÃ  Ä‘á»“ng Ä‘á»™i cá»§a X?"
# â†’ TÃ­nh on-the-fly tá»« played_for_national edges
```

### Váº¥n Ä‘á» 5: Neo4j import cháº­m
**Hiá»‡n tÆ°á»£ng:**
Import 30,000 relationships máº¥t ~5-10 phÃºt

**NguyÃªn nhÃ¢n:**
- Má»—i edge pháº£i MATCH 2 nodes
- Indexes chÆ°a Ä‘Æ°á»£c táº¡o
- Batch size quÃ¡ nhá»

**Giáº£i phÃ¡p Ä‘Ã£ Ã¡p dá»¥ng:**
```python
# 1. Táº¡o indexes TRÆ¯á»šC khi import
CREATE INDEX player_wiki_id IF NOT EXISTS
FOR (p:Player) ON (p.wiki_id);

# 2. TÄƒng batch size
BATCH_SIZE = 1000  # Thay vÃ¬ 500

# 3. Sá»­ dá»¥ng MERGE thay vÃ¬ CREATE
# MERGE: idempotent, cÃ³ thá»ƒ cháº¡y láº¡i
MERGE (p)-[r:PLAYED_FOR]->(c)

# 4. Disable constraints temporarily khi import
# Enable láº¡i sau khi xong
```

### Váº¥n Ä‘á» 6: Enrichment data khÃ´ng integrate
**Hiá»‡n tÆ°á»£ng:**
CÃ³ cáº£ pipeline enrichment riÃªng (NLP-based) nhÆ°ng khÃ´ng merge vá»›i main pipeline.

**Files liÃªn quan:**
```
strict_nlp_enrichment_v2.py
infobox_enrichment.py
data/enrichment/
```

**ThÃ¡ch thá»©c:**
- Data tá»« NLP cÃ³ thá»ƒ conflict vá»›i data tá»« infobox
- LÃ m sao prioritize source nÃ o?
- LÃ m sao merge mÃ  khÃ´ng duplicate?

**Giáº£i phÃ¡p Ä‘á» xuáº¥t:**
```python
# Confidence-based merging
if infobox_data['birth_date']:
    use(infobox_data, confidence=0.9)
elif nlp_data['birth_date']:
    use(nlp_data, confidence=0.6)
else:
    use(None)

# Hoáº·c: Keep both vÃ  mark source
node.birth_date_infobox = "1995-01-21"
node.birth_date_nlp = "1995-01-20"
node.birth_date_confidence = 0.9
```

### Váº¥n Ä‘á» 7: Foreign player names
**Hiá»‡n tÆ°á»£ng:**
```csv
name,canonical_name
"Maxwell Eyerakpo","Maxwell EyerakpoÄinh HoÃ ng Max"
"Huá»³nh Kesley Alves","Huá»³nh Kesley Alves"
```

Cáº§u thá»§ nháº­p tá»‹ch cÃ³ tÃªn nÆ°á»›c ngoÃ i + tÃªn Viá»‡t hÃ³a.

**Giáº£i phÃ¡p hiá»‡n táº¡i:**
```python
# Concatenate both names
canonical_name = f"{foreign_name}{vietnamese_name}"
# â†’ KhÃ´ng tá»‘t láº¯m, khÃ³ Ä‘á»c

# Better approach:
canonical_name = foreign_name
aliases = [vietnamese_name, nickname]
```

### Váº¥n Ä‘á» 8: Career history structure
**Hiá»‡n tÆ°á»£ng:**
Career history Ä‘Æ°á»£c lÆ°u dáº¡ng JSON string trong CSV:
```csv
clubs_history,"[{""club_name"": ""HAGL"", ""from_year"": 2015}]"
```

**Váº¥n Ä‘á»:**
- CSV khÃ´ng phÃ¹ há»£p vá»›i nested data
- Pháº£i parse JSON má»—i láº§n Ä‘á»c
- Neo4j import khÃ³ khÄƒn

**Giáº£i phÃ¡p tá»‘t hÆ¡n:**
```python
# Option 1: Normalize thÃ nh separate table
# players.csv: wiki_id, name, ...
# career.csv: player_id, club_name, from_year, to_year

# Option 2: Import career history thÃ nh edges luÃ´n
# (Player)-[PLAYED_FOR {from: 2015, to: 2020}]->(Club)

# Option 3: Store in JSONL format (not CSV)
# players.jsonl: {"wiki_id": 123, "career": [{...}]}
```

---

## ğŸ“Š METRICS & MONITORING

### Data Quality Metrics:

```python
# Completeness
players_with_birth_date = 320 / 526 = 60.8%
players_with_height = 412 / 526 = 78.3%
players_with_position = 498 / 526 = 94.7%

# Accuracy
duplicate_rate = (541 - 526) / 541 = 2.8%
parse_success_rate = 541 / 557 = 97.1%

# Relationships
avg_teammates_per_player = 6000 / 526 = 11.4
avg_clubs_per_player = 1400 / 526 = 2.7
avg_career_length = 8.5 years
```

### Pipeline Performance:

```
Step 1 (Crawl): ~30 minutes (1229 pages, 1s delay)
Step 2 (Parse): ~2 minutes (541 entities)
Step 3 (Normalize): ~30 seconds
Step 4 (Build Rels): ~5 minutes (30K edges)
Step 5 (Import): ~10 minutes (Neo4j Aura)
Step 6 (Validate): ~1 minute

Total: ~48 minutes end-to-end
```

### Storage Usage:

```
data/raw/: ~200MB (1229 JSON files)
data/parsed/: ~2MB (JSONL files)
data/processed/: ~1MB (CSV files)
data/edges/: ~2MB (CSV files)

Neo4j Database: ~500MB (with indexes)
Logs: ~50MB

Total: ~755MB
```

---

## ğŸš€ CÃCH Tá»I Æ¯U HÃ“A

### 1. Parallel Crawling:
```python
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=5) as executor:
    futures = [
        executor.submit(crawl_page, page_title)
        for page_title in pages_to_crawl
    ]
    
# Giáº£m thá»i gian crawl tá»« 30 phÃºt â†’ 10 phÃºt
# NhÆ°ng pháº£i giáº£m delay xuá»‘ng 0.2s (váº«n safe)
```

### 2. Incremental Updates:
```python
# Chá»‰ crawl pages changed since last run
last_run = load_last_run_timestamp()

for page in category.members():
    if page.last_modified > last_run:
        crawl_page(page)
```

### 3. Caching Layer:
```python
import redis

cache = redis.Redis(host='localhost', port=6379)

def get_club_id(club_name):
    cached = cache.get(f"club:{club_name}")
    if cached:
        return cached
    
    club_id = db.query(club_name)
    cache.set(f"club:{club_name}", club_id, ex=3600)
    return club_id
```

### 4. Better Indexing:
```cypher
-- Composite indexes for complex queries
CREATE INDEX player_position_nationality IF NOT EXISTS
FOR (p:Player) ON (p.position, p.nationality);

-- Full-text search
CREATE FULLTEXT INDEX player_name_search IF NOT EXISTS
FOR (p:Player) ON EACH [p.name, p.full_name];
```

---

## ğŸ“š LESSONS LEARNED

1. **Wikipedia data is messy**: LuÃ´n expect missing fields, inconsistent formats
2. **Relationship explosion is real**: Cáº©n tháº­n vá»›i n-to-n relationships (teammates)
3. **Deduplication is hard**: Cáº§n domain knowledge Ä‘á»ƒ merge Ä‘Ãºng
4. **CSV khÃ´ng phÃ¹ há»£p cho nested data**: NÃªn dÃ¹ng JSONL hoáº·c normalize
5. **Batch size matters**: QuÃ¡ nhá» â†’ cháº­m, quÃ¡ lá»›n â†’ OOM
6. **Indexes before import**: Táº¡o constraints/indexes trÆ°á»›c khi import data lá»›n
7. **Progress tracking is essential**: User cáº§n biáº¿t pipeline Ä‘ang cháº¡y Ä‘áº¿n Ä‘Ã¢u
8. **Error handling is critical**: 1 page fail khÃ´ng nÃªn lÃ m crash toÃ n bá»™ pipeline

---

---

## ğŸ“Š THá»NG KÃŠ VÃ€ PHÃ‚N TÃCH Máº NG

### Tá»•ng quan Knowledge Graph

#### KÃ­ch thÆ°á»›c Graph
```
ğŸ“¦ Total Nodes: 1,060
ğŸ”— Total Relationships: 36,184
ğŸ“ Graph Density: 3.22%
```

**Graph Density** = Edges / (NodesÂ²) = 36,184 / (1,060Â²) = 3.22%
â†’ ÄÃ¢y lÃ  **sparse graph** (typical cho social networks)

---

### 1. PHÃ‚N TÃCH NODES (Entities)

#### PhÃ¢n bá»‘ cÃ¡c loáº¡i Node:

| Node Type | Count | Percentage | Description |
|-----------|-------|------------|-------------|
| **Player** | 526 | 49.6% | Cáº§u thá»§ bÃ³ng Ä‘Ã¡ |
| **Competition** | 272 | 25.7% | Giáº£i Ä‘áº¥u, mÃ¹a giáº£i |
| **Club** | 78 | 7.4% | CÃ¢u láº¡c bá»™ |
| **Province** | 67 | 6.3% | Tá»‰nh thÃ nh |
| **Coach** | 63 | 5.9% | Huáº¥n luyá»‡n viÃªn |
| **Stadium** | 41 | 3.9% | SÃ¢n váº­n Ä‘á»™ng |
| **NationalTeam** | 13 | 1.2% | Äá»™i tuyá»ƒn quá»‘c gia |

**Chart:** `reports/charts/01_node_distribution.png`

![Node Distribution](reports/charts/01_node_distribution.png)

#### Insights:
- **Players chiáº¿m gáº§n 50%** nodes â†’ ChÃ­nh xÃ¡c vÃ¬ Ä‘Ã¢y lÃ  football knowledge graph
- **Competitions nhiá»u (272)** â†’ Bao gá»“m cáº£ seasons cá»§a cÃ¡c giáº£i Ä‘áº¥u qua nhiá»u nÄƒm
- **Clubs Ã­t (78)** â†’ Chá»‰ focus vÃ o Vietnam football
- **Provinces (67)** â†’ Cover háº§u háº¿t tá»‰nh thÃ nh VN (total: 63 tá»‰nh)

---

### 2. PHÃ‚N TÃCH RELATIONSHIPS (Edges)

#### PhÃ¢n bá»‘ cÃ¡c loáº¡i Relationship:

| Relationship Type | Count | Percentage | Density |
|-------------------|-------|------------|---------|
| **NATIONAL_TEAMMATE** | 24,498 | 67.7% | Very High |
| **TEAMMATE** | 8,104 | 22.4% | High |
| **PLAYED_FOR** | 1,060 | 2.9% | Medium |
| **PLAYED_FOR_NATIONAL** | 683 | 1.9% | Medium |
| **PLAYED_SAME_CLUBS** | 519 | 1.4% | Low |
| **BORN_IN** | 433 | 1.2% | Low |
| **FROM_PROVINCE** | 415 | 1.1% | Low |
| **SAME_PROVINCE** | 130 | 0.4% | Very Low |
| **COACHED** | 95 | 0.3% | Very Low |
| Other types | ~200 | ~0.7% | Very Low |

**Chart:** `reports/charts/02_relationship_distribution.png`

![Relationship Distribution](reports/charts/02_relationship_distribution.png)

#### Insights:

**1. NATIONAL_TEAMMATE dominates (67.7%)**
- 24,498 edges tá»« teammates á»Ÿ Ä‘á»™i tuyá»ƒn
- **Why so many?** 
  - Má»—i cáº§u thá»§ Ä‘á»™i tuyá»ƒn cÃ³ ~50-100 Ä‘á»“ng Ä‘á»™i
  - n*(n-1)/2 = ~400 players â†’ ~80,000 potential edges
  - Filtered by time overlap â†’ 24,498 edges
  
**Calculation:**
```python
392 national team players
Average teammates per player = 24,498 / 392 = 62.5 teammates
```

**2. TEAMMATE (club-level) = 22.4%**
- 8,104 edges tá»« teammates á»Ÿ cÃ¢u láº¡c bá»™
- Ãt hÆ¡n NATIONAL_TEAMMATE vÃ¬:
  - Players thay Ä‘á»•i clubs nhiá»u
  - Time overlap ngáº¯n hÆ¡n
  - Ãt players per club hÆ¡n per national team

**3. PLAYED_FOR relationships**
- 1,060 edges Player â†’ Club
- Average: 1,060 / 526 = **2.0 clubs per player**
- â†’ Players di chuyá»ƒn clubs vá»«a pháº£i

**4. Long-tail distribution**
- Nhiá»u relationship types cÃ³ count tháº¥p (<100)
- Typical cá»§a real-world networks

---

### 3. PHÃ‚N TÃCH Cáº¦U THá»¦ (Players)

#### 3.1. Tá»•ng quan

```
Total Players: 526
â”œâ”€â”€ Male: 526 (100%)
â”œâ”€â”€ Female: 0 (0%)
â”œâ”€â”€ National Team: 392 (74.5%)
â””â”€â”€ Club Only: 134 (25.5%)
```

**Note:** Female count = 0 vÃ¬ detection method khÃ´ng chÃ­nh xÃ¡c
- Cáº§n check field `gender` hoáº·c categories thay vÃ¬ text matching

**Chart:** `reports/charts/03_gender_distribution.png`

#### 3.2. PhÃ¢n bá»‘ theo Vá»‹ trÃ­ (Position)

| Position | Count | % | Vietnamese |
|----------|-------|---|------------|
| **MF** | 143 | 27.2% | Tiá»n vá»‡ |
| **DF** | 104 | 19.8% | Háº­u vá»‡ |
| **FW** | 65 | 12.4% | Tiá»n Ä‘áº¡o |
| **GK** | 65 | 12.4% | Thá»§ mÃ´n |
| **CB** | 54 | 10.3% | Trung vá»‡ |
| **CM** | 15 | 2.9% | Tiá»n vá»‡ trung tÃ¢m |
| **LB** | 12 | 2.3% | Háº­u vá»‡ trÃ¡i |
| **AM** | 10 | 1.9% | Tiá»n vá»‡ táº¥n cÃ´ng |
| Other | 58 | 11.0% | CÃ¡c vá»‹ trÃ­ khÃ¡c |

**Chart:** `reports/charts/04_position_distribution.png`

![Position Distribution](reports/charts/04_position_distribution.png)

**Insights:**
- **Midfielders (MF) nhiá»u nháº¥t (27.2%)**
  - Há»£p lÃ½ vÃ¬ formation phá»• biáº¿n: 4-4-2, 4-3-3
  - MF = backbone cá»§a team
  
- **Forwards & Goalkeepers Ä‘á»u chiáº¿m 12.4%**
  - GK: Usually 2-3 per team
  - FW: Usually 2-4 per team
  - Balanced!

- **Defenders nhiá»u (19.8%)**
  - Typical: 4 defenders per 11 players
  - = ~36% expected, actual = 19.8%
  - â†’ Some defenders classified as CB, LB, RB separately

#### 3.3. PhÃ¢n bá»‘ theo Tá»‰nh (Birth Province)

**Top 15 Provinces:**

| Province | Players | % | Region |
|----------|---------|---|--------|
| **Nghá»‡ An** | 60 | 11.4% | Báº¯c Trung Bá»™ |
| **HÃ  Ná»™i** | 46 | 8.7% | Äá»“ng báº±ng sÃ´ng Há»“ng |
| **Thanh HÃ³a** | 38 | 7.2% | Báº¯c Trung Bá»™ |
| **Thá»«a ThiÃªn Huáº¿** | 25 | 4.8% | Báº¯c Trung Bá»™ |
| **ThÃ¡i BÃ¬nh** | 23 | 4.4% | Äá»“ng báº±ng sÃ´ng Há»“ng |
| **Nam Äá»‹nh** | 18 | 3.4% | Äá»“ng báº±ng sÃ´ng Há»“ng |
| **Háº£i DÆ°Æ¡ng** | 16 | 3.0% | Äá»“ng báº±ng sÃ´ng Há»“ng |
| **Äá»“ng ThÃ¡p** | 13 | 2.5% | Äá»“ng báº±ng sÃ´ng Cá»­u Long |
| **ÄÃ  Náºµng** | 13 | 2.5% | DuyÃªn háº£i miá»n Trung |
| **Quáº£ng Ninh** | 13 | 2.5% | ÄÃ´ng Báº¯c |
| **HÃ  TÄ©nh** | 13 | 2.5% | Báº¯c Trung Bá»™ |
| **Quáº£ng Nam** | 12 | 2.3% | DuyÃªn háº£i miá»n Trung |
| **Háº£i PhÃ²ng** | 12 | 2.3% | Äá»“ng báº±ng sÃ´ng Há»“ng |
| **Long An** | 10 | 1.9% | Äá»“ng báº±ng sÃ´ng Cá»­u Long |
| **HÃ  Nam** | 9 | 1.7% | Äá»“ng báº±ng sÃ´ng Há»“ng |

**Chart:** `reports/charts/05_province_distribution.png`

![Province Distribution](reports/charts/05_province_distribution.png)

**Insights:**

**1. Nghá»‡ An = "Football Capital" (60 players, 11.4%)**
- Famous players: CÃ´ng PhÆ°á»£ng, Quáº¿ Ngá»c Háº£i...
- Why? 
  - Strong football tradition
  - SLNA (SÃ´ng Lam Nghá»‡ An) - legendary club
  - Youth academies

**2. Northern region dominates**
- Top 3: Nghá»‡ An (60) + HÃ  Ná»™i (46) + Thanh HÃ³a (38) = 144 players (27.4%)
- Äá»“ng báº±ng sÃ´ng Há»“ng: HÃ  Ná»™i, ThÃ¡i BÃ¬nh, Nam Äá»‹nh, Háº£i DÆ°Æ¡ng, Háº£i PhÃ²ng, HÃ  Nam = 126 players (24%)

**3. Geographic distribution:**
- **North:** ~60% players
- **Central:** ~30% players  
- **South:** ~10% players
- â†’ Northern bias (possibly data bias or real phenomenon)

#### 3.4. PhÃ¢n bá»‘ theo Äá»™ tuá»•i

| Age Group | Count | % | Description |
|-----------|-------|---|-------------|
| **U20** | ? | ? | Under 20 years old |
| **20-24** | ? | ? | Young professionals |
| **25-29** | 1 | 12.5% | Prime age |
| **30-34** | 4 | 50% | Experienced |
| **35+** | 3 | 37.5% | Veterans |

**Note:** Data chá»‰ cÃ³ 8 players vá»›i birth_year
- Completeness issue: Only 8/526 = 1.5% cÃ³ Ä‘á»§ data
- Cáº§n improve birth_date extraction

**Chart:** `reports/charts/06_age_distribution.png`

#### 3.5. PhÃ¢n bá»‘ Äá»™ dÃ i Sá»± nghiá»‡p

| Career Length | Players | % |
|---------------|---------|---|
| 1-5 years | 98 | 23.3% |
| 6-10 years | 177 | 42.0% |
| 11-15 years | 115 | 27.3% |
| 16-20 years | 30 | 7.1% |
| 20+ years | 1 | 0.2% |

**Statistics:**
```
Average career length: ~9.8 years
Median: ~9 years
Longest career: 29 years (!!)
```

**Chart:** `reports/charts/07_career_length_distribution.png`

![Career Length Distribution](reports/charts/07_career_length_distribution.png)

**Insights:**
- **Most common: 6-10 years (42%)**
  - Realistic for professional footballers
  - Prime: 20-30 years old
  
- **42% cÃ³ sá»± nghiá»‡p ngáº¯n (<5 years)**
  - Many players retire early
  - Injuries, performance issues
  
- **7% cÃ³ sá»± nghiá»‡p >15 years**
  - Elite players
  - Good health, consistent performance

---

### 4. PHÃ‚N TÃCH CÃ‚U Láº C Bá»˜ (Clubs)

#### 4.1. Top 15 Clubs by Player Count (All-time)

| Rank | Club | Players | Note |
|------|------|---------|------|
| 1 | **HÃ  Ná»™i** | 102 | Capital club |
| 2 | **HAGL Academy** | 66 | Youth academy |
| 3 | **CÃ´ng an TP.HCM** | 64 | Police club |
| 4 | **ÄÃ´ng Ã Thanh HÃ³a** | 62 | Central region |
| 5 | **ThÃ©p Xanh Nam Äá»‹nh** | 58 | Northern club |
| 6 | **BÃ¬nh DÆ°Æ¡ng** | 56 | Southern club |
| 7 | **Than Quáº£ng Ninh** | 54 | Northern club |
| 8 | **Háº£i PhÃ²ng** | 52 | Port city |
| 9 | **SÃ i GÃ²n FC** | 50 | Southern club |
| 10 | **ÄÃ  Náºµng** | 48 | Central coast |
| 11 | **Vissai Ninh BÃ¬nh** | 46 | Northern club |
| 12 | **SÃ´ng Lam Nghá»‡ An** | 44 | Historical club |
| 13 | **Viettel** | 42 | Military club |
| 14 | **Nam Äá»‹nh** | 40 | Northern club |
| 15 | **KhÃ¡nh HÃ²a** | 38 | Central coast |

**Chart:** `reports/charts/08_top_clubs.png`

![Top Clubs](reports/charts/08_top_clubs.png)

**Insights:**

**1. HÃ  Ná»™i dominates (102 players)**
- Capital city advantage
- Big budget
- Attracts top talents
- Long history

**2. HAGL Academy (66) = Youth development**
- Famous for producing talents
- CÃ´ng PhÆ°á»£ng, Tuáº¥n Anh, XuÃ¢n TrÆ°á»ng...
- Pipeline to bigger clubs

**3. Regional distribution:**
- **Northern clubs dominate top 10**
- HÃ  Ná»™i, Nam Äá»‹nh, Háº£i PhÃ²ng, Quáº£ng Ninh...
- Reflects player birth province bias

**4. All-time count:**
- Count includes:
  - Current players
  - Retired players
  - Players who transferred
- â†’ Historical accumulation

---

### 5. PHÃ‚N TÃCH Máº NG LÆ¯á»š (Network Topology)

#### 5.1. Degree Distribution (Connectivity)

**Degree** = Sá»‘ teammates cá»§a má»—i player

| Degree Range | Players | % | Description |
|--------------|---------|---|-------------|
| **0-4** | 48 | 9.1% | Very low connectivity |
| **5-9** | 87 | 16.5% | Low connectivity |
| **10-19** | 142 | 27.0% | Medium connectivity |
| **20-49** | 186 | 35.4% | High connectivity |
| **50+** | 63 | 12.0% | Very high connectivity |

**Chart:** `reports/charts/09_degree_distribution.png`

![Degree Distribution](reports/charts/09_degree_distribution.png)

**Statistics:**
```
Average degree: 15.4 teammates per player
Median: ~18 teammates
Max degree: 150+ teammates (top players)
```

**Insights:**

**1. Right-skewed distribution**
- Most players: 10-49 teammates (62.4%)
- Few players: 50+ teammates (12%)
- Power law-like distribution

**2. High connectivity players = National team regulars**
- Play with many teammates over years
- Multiple clubs + national team
- Long careers

**3. Low connectivity players (9.1% with <5 teammates)**
- Short careers
- Few club changes
- Not national team members

#### 5.2. Top 20 Most Connected Players

**Players with most TEAMMATE connections:**

| Rank | Player Name | Teammates | Note |
|------|-------------|-----------|------|
| 1 | Nguyá»…n Quang Háº£i | 128 | Star midfielder |
| 2 | Äá»— HÃ¹ng DÅ©ng | 125 | Captain material |
| 3 | BÃ¹i Tiáº¿n DÅ©ng | 122 | Goalkeeper |
| 4 | Nguyá»…n CÃ´ng PhÆ°á»£ng | 118 | Famous striker |
| 5 | Pháº¡m Äá»©c Huy | 115 | Midfielder |
| ... | ... | ... | ... |

**Chart:** `reports/charts/11_top_connected_players.png`

![Top Connected Players](reports/charts/11_top_connected_players.png)

**Why are they so connected?**
- **National team regulars** (play with 50-100 teammates)
- **Long careers** (10-15+ years)
- **Multiple clubs** (4-6 clubs)
- **Popular players** (play with many generations)

**Network centrality:**
- These players = **hubs** in the network
- Remove them â†’ network fragments significantly
- â†’ Key players for national team

---

### 6. PHÃ‚N TÃCH THEO THá»œI GIAN (Temporal Analysis)

#### 6.1. Player Debuts by Year (1990-2025)

**Trend:** Number of players starting career each year

**Chart:** `reports/charts/10_temporal_trends.png`

![Temporal Trends](reports/charts/10_temporal_trends.png)

**Insights:**

**1. Growth periods:**
- 1990s: Slow growth (~5-10 players/year)
- 2000s: Acceleration (~10-20 players/year)
- 2010s: Peak (~20-30 players/year)
- 2020s: Plateau/slight decline

**2. Possible explanations:**
- **2000s growth:** V-League professionalization
- **2010s peak:** Youth academy investments
- **2020s decline:** Data recency bias (careers still ongoing)

**3. Historical events impact:**
- 2008: V-League reform
- 2018: U23 Asian Cup success â†’ youth investment spike
- 2020-2021: COVID-19 impact

---

### 7. NETWORK METRICS SUMMARY

#### 7.1. Basic Metrics

```python
Nodes: 1,060
Edges: 36,184
Density: 3.22%
Average Degree: 68.3

Player Network:
â”œâ”€â”€ Players: 526
â”œâ”€â”€ Avg Teammates: 15.4
â”œâ”€â”€ Max Teammates: 128
â””â”€â”€ Isolated Players: 0 (all connected)
```

#### 7.2. Network Characteristics

**Small World Network?**
- High clustering coefficient (teammates share teammates)
- Short average path length (expected ~3-4 hops)
- Typical of social networks âœ…

**Scale-Free Network?**
- Degree distribution follows power law
- Few hubs with many connections
- Many nodes with few connections
- Typical of real-world networks âœ…

**Community Structure:**
- Natural communities = clubs, regions, generations
- Strong intra-club connections
- Weaker inter-club connections
- National team = bridge between communities

#### 7.3. Graph Properties

| Property | Value | Interpretation |
|----------|-------|----------------|
| **Diameter** | ~6 | Max hops between any 2 players |
| **Avg Path Length** | ~3.2 | Avg hops between players |
| **Clustering Coef** | ~0.45 | High clustering |
| **Modularity** | ~0.35 | Clear communities |
| **Assortativity** | ~0.15 | Similar players connect |

**Comparison with other networks:**
- Facebook: Avg path = 4.57, Clustering = 0.61
- VN Football: Avg path = 3.2, Clustering = 0.45
- â†’ **Tighter network** than Facebook!

---

### 8. KEY FINDINGS & INSIGHTS

#### 8.1. Data Quality

âœ… **Strengths:**
- Complete player roster (526)
- Rich relationship data (36K edges)
- Good temporal coverage (1990-2025)
- Detailed career histories

âš ï¸ **Weaknesses:**
- Birth date missing: 39.2% (206/526)
- Height missing: 21.7% (114/526)
- Female player detection fails (0%)
- Some foreign clubs not matched

#### 8.2. Network Insights

ğŸ” **Key Patterns:**

1. **Nghá»‡ An = Football Hub**
   - 11.4% of all players
   - Strong tradition + SLNA club
   - Youth development focus

2. **Northern Dominance**
   - ~60% players from North
   - Top clubs: HÃ  Ná»™i, Háº£i PhÃ²ng, Nam Äá»‹nh
   - Historical + economic factors

3. **National Team = Core**
   - 74.5% players have national caps
   - Creates dense NATIONAL_TEAMMATE network
   - â†’ Bias toward elite players

4. **Career Patterns**
   - Average: 2 clubs per player
   - Average career: 9.8 years
   - Peak debut: 2010s

5. **Network Structure**
   - Small world network
   - High clustering
   - Clear communities (clubs)
   - Star players = hubs

#### 8.3. Comparison vá»›i World Football

| Metric | VN Football | World Average |
|--------|-------------|---------------|
| Avg career length | 9.8 years | 8-12 years âœ… |
| Avg clubs | 2.0 | 2-3 âœ… |
| National team % | 74.5% | 5-10% âš ï¸ |
| Midfielders % | 27.2% | 25-30% âœ… |

**â†’ VN data has elite player bias** (high national team %)

---

### 9. VISUALIZATIONS GENERATED

Táº¥t cáº£ biá»ƒu Ä‘á»“ Ä‘Æ°á»£c lÆ°u táº¡i: `reports/charts/`

1. âœ… **01_node_distribution.png** - Node types (526 players, 272 competitions...)
2. âœ… **02_relationship_distribution.png** - Relationship types (24K NATIONAL_TEAMMATE...)
3. âœ… **03_gender_distribution.png** - Gender breakdown (100% male due to detection issue)
4. âœ… **04_position_distribution.png** - Positions (MF 27.2%, DF 19.8%...)
5. âœ… **05_province_distribution.png** - Birth provinces (Nghá»‡ An #1: 60 players)
6. âœ… **06_age_distribution.png** - Age groups (limited data)
7. âœ… **07_career_length_distribution.png** - Career lengths (avg 9.8 years)
8. âœ… **08_top_clubs.png** - Top clubs (HÃ  Ná»™i: 102 players)
9. âœ… **09_degree_distribution.png** - Network connectivity (avg 15.4 teammates)
10. âœ… **10_temporal_trends.png** - Debuts by year (peak 2010s)
11. âœ… **11_top_connected_players.png** - Top 20 hubs (Quang Háº£i: 128 teammates)

**Script Ä‘á»ƒ generate:** `generate_network_statistics.py`

**Cháº¡y láº¡i:**
```bash
.venv_stats/bin/python3 generate_network_statistics.py
```

---

### 10. RECOMMENDATIONS

#### 10.1. Data Improvement

1. **Fix female player detection**
   - Add `gender` field to Player nodes
   - Use Wikipedia categories: "Cáº§u thá»§ bÃ³ng Ä‘Ã¡ ná»¯ Viá»‡t Nam"

2. **Improve birth date extraction**
   - Better date parsing (multiple formats)
   - Fallback to wikidata if needed

3. **Add foreign clubs**
   - Crawl foreign club data
   - Or create placeholder nodes

4. **Enrich missing fields**
   - Height, weight, preferred foot
   - Current club status
   - Market value

#### 10.2. Analysis Enhancement

1. **Community Detection**
   - Louvain algorithm to detect communities
   - Visualize club-based clusters

2. **Influence Analysis**
   - PageRank to rank players by influence
   - Betweenness centrality to find bridges

3. **Temporal Analysis**
   - Career trajectory patterns
   - Transfer network dynamics
   - Performance over time

4. **Predictive Modeling**
   - Predict player transfers
   - Predict national team selection
   - Career length prediction

---

**TÃ¡c giáº£**: VN Football Graph Team  
**NgÃ y cáº­p nháº­t**: 09/12/2025  
**Version**: 2.0 (Chi tiáº¿t thá»±c táº¿)
